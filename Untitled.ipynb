{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data...\n",
      "done processing data\n",
      "counting tags...\n",
      "done counting tags.\n",
      "{'iPod': 'ipod', 'â\\x80\\x95': 'â\\x80\\x99', \"Jonathan's\": \"thomason's\", 'Job': 'job', 'bias': 'asia', 'footballer': 'rockefeller', 'sing': 'using', 'Sky': 'sky', 'Mert': 'alert', 'Parade': 'trade', 'Marie': 'marie', 'Tour': 'your', 'Tuareg': 'region', 'CRIMINAL\"': 'schmooze\"', '2.99': '22.93', 'RT': 'on', 'Cable': 'table', \"week's\": 'weeks', 'Call': 'call', 'Mo': 'on', 'Awaz': 'lazy', \"We're\": \"we're\", 'Romo': 'promo', 'Gaiman': 'hitman', 'BusinessWeek': 'businessweek', 'AT': 'on', 'FREE': '@aol', 'If': 'of', 'disassembled': 'disappointed', 'Johansson': 'ericsson', 'NGO': 'ray', 'Tucson': 'wesson', 'AmazonBasics': '@metrolyrics', 'Walking': 'talking', 'Mishaal': 'removal', 'Camp': 'lamp', 'Cape': 'shape', 'alexisandsalomonseafoods@yahoo.com': 'http://www.beeremovalspecialist.com', \"Britain's\": \"#bahrain's\", 'Hint': 'into', 'rejects\"': 'reject', 'Attend': 'attend', 'Fi': 'it', 'Tripoli': 'policies', 'C': 'j', 'Hop': 'top', 'amount': 'account', 'sch': 'such', 'musing': 'using', 'Preservation': 'innovation', 'Dow': 'now', 'Live': 'live', 'girls': \"girl'\", 'All': 'all', 'Justin': 'justin', 'Edinburgh': 'copyright', 'owe': 'now', 'CRUSH': 'death', 'masterpiece': 'masterpieces', 'ousted': 'trusted', 'Business': 'business', 'inbuilt': '\"guilty', \"Here's\": \"here's\", 'Welcome': 'welcome', 'Since': 'since', 'Mondays': 'airways', 'Very': 'very', 'intended': 'nintendo', 'Attack': 'attack', 'Museum\"': '\"racism', 'Ghazals': 'animals', 'initiatives': 'initiative', 'Web': 'web', 'Roald': 'waldo', 'Suck': 'huck', 'Rangers': 'avengers', 'Consumer': 'consumer', 'Cohn': 'john', 'In': 'on', 'HP': 'on', 'Defender': '\"bender\"', 'Strategy': '#egypt', 'Gasoline': 'headline', 'Suntec': 'protect', 'straightsilverinc': '@backstreetboys', 'Paris': 'paris', 'Cover': 'over.', 'hat': 'that', 'aka': 'kau', '\\\\o/': '/gg', 'Learn': 'learn', 'Apple': 'apple', 'kicked': 'wicked', 'Just': 'just', 'Rescue': 'avenue', 'Drams': 'dreams', 'Need': 'need', 'Names': 'james', 'prefers': 'prefer', 'frozen': 'fronts', 'wears': 'years', 'Go-Between': 'between', 'Dolphin': 'dolphins', 'Thanks': 'thanks', 'His': 'his', 'Friends': 'friends', 'Book': 'look', 'iPad\"': '\"it\\'s', 'Subaru': 'fruity', 'Buddhist': 'history', 'FOR': 'ray', 'League': 'league', 'Gufiaito': 'editorial', '[REPORT]': 'creating', 'Japan': 'japan', 'rich': 'rick', 'IR': 'on', 'queue': 'queen', '3D': '23', 'Darklighter': 'freighter', 'crossed': 'across', 'Breaking': 'breaking', 'wife': 'life', 'Al-Bayadah': '@ghadahr', 'John': 'john', 'Volatility': 'capability', 'theme': 'them', 'iPa': 'via', 'Chicago': 'chicago', \"drones'\": 'drone', 'ID': 'on', 'eBook': 'looks', 'coaching': 'watching', 'Wednesday': '#tunesday', 'books': '#books', 'Black': 'black', 'Pre': 'are', 'International': 'international', 'dare': 'dares', 'Support': 'support', 'correct': 'director', 'eIndia': '\"india', 'Dan': 'fan', 'Decision': 'decision', 'entrees': \"centre's\", 'sexiest': 'easiest', 'ft': 'of', 'Quotes': 'quotes', 'Middle': 'middle', 'index': 'indexes', 'Read': 'head', 'One': 'new', 'Bragg': 'ragged', 'Children': 'children', 'Piracy': 'legacy', 'Antonia': 'pneumonia', 'Roundu': 'hindu', 'Earn': 'earn', 'opinion': 'session', 'Yikes': 'likes', 'people.They': 'people.\"', 'Tech': 'tech', 'icons': 'icon', 'Blessings': 'piercings', 'Public': 'public', 'Sherman': 'herman', 'shall': 'hall', 'Hummer': 'summer', 'reply': 'repay', 'NICKELBACK': 'reputation', 'Expand': 'random', 'occupied': '#occupy', 'Portrays': 'displays', 'casualty': 'ziprealty', 'Wins': 'wins', '1-1': '2-1', 'Each': 'each', 'Briquel': 'clueless', 'cloths': 'clothes', 'Recovering': 'weathering', 'Your': 'your', 'LA': 'on', 'Vs': 'is', 'Dominated': 'nominated', 'Dalai': 'alain', 'IPO': 'ray', 'itself': 'myself', 'Dominic': 'nicole', 'Learned': 'earned', 'spacefiller': 'rockefeller', 'Pooh': 'john', \"Anger.'\": \"today's\", 'Carlos': 'closed', 'Pamela': 'homeland', 'ie': 'it', 'Same': 'game', 'benefit': 'benefits', 'FACEBOOK': 'creating', 'Alan': 'land', 'egyptian': '#egypt', '\"Former': 'former', 'For': 'for', 'translate': 'transfer', 'Avenue': 'avenue', 'Ian': 'fan', 'campaigners': 'partnership', 'Reminder': '\"bender\"', 'there.\"': '\"there', 'Link': 'link', '899': '994', 'Governor': 'governorship', 'ACTA': '@aol', 'Lava': 'naval', \"'USC'\": \"fans'\", 'protesters': 'protests', 'racist': 'racism', 'Check': 'check', 'compa': 'company', 'Birth': 'birth', 'tem': 'tema', 'A': 'j', 'Rose-colored': 'ingredients', 'Saud': 'audi', 'younger': 'young', 'Sharp': 'carpet', 'award': 'awards', 'Starr': 'barry', 'Kenyan': 'libyan', 'Producers': 'producers', 'USA': 'ray', 'Ouch': 'much', 'renewed': 'ordered', 'Barbara': 'mubarak', 'records': 'record', 'print': 'sprint', 'SPB': 'ray', 'Poly50': 'â£500m', 'Mad': 'bad', 'calculate': 'populated', 'blessed': 'stressed', 'Welch': 'cheap', 'Process': 'success', 'triggring': 'featuring', 'Jill': 'hill', 'parent': 'parenting', 'Administration': 'demonstration', \"We've\": \"we've\", 'Oh': 'oh', 'feeling': 'felling', 'retail': 'retailers', 'Credits': 'credits', 'Apr': 'pro', 'Champ': 'champ', 'Entres': 'actress', '+300': '300', 'America': 'america', 'Hollywood': 'hollywood', 'booth': '#boots', 'OF': 'on', 'Francisco': 'discovery', 'gee': 'get', 'Better': 'better', ';-)': 'p):', 'HCC': 'ray', 'AL': 'on', 'Export': 'report', 'WCCO': '@aol', 'Sale': 'sale', 'Lifestyle': 'lifestyle', 'Any': 'nyt', 'Of': 'of', 'Alexander': 'commander', 'Australia': 'australia', 'Stores': 'stores', 'After': 'after', 'Hillary': 'hillary', 'Arsenal': 'arsenal', '~Maxim': 'maximize', 'Associates': 'associates', 'Otellini': 'collini', 'pads': 'ipads', 'Shaklee-': 'drive-in', 'LIVE': '@aol', 'Marc': 'march', 'Gillard': 'richard', 'customs': 'custom', 'Dale': 'sale', 'Pakistan': 'pakistan', 'Hugo': 'hugo', 'Profit': 'profit', 'Analysis': 'assisted', 'Whiskies': 'cookies', \"'Monster\": 'monsters', 'Twanging': 'hanging', 'Napoleon': 'surgeons', 'Forrest': 'arrests', 'REPORT': 'breaks', 'Pipeline': 'sideliners', 'driving': 'giving', 'MSN': 'ray', '15.1': '7.15', 'Radio': 'radio', 'Allen\"': '\"smith', 'Disruption': 'disruption', \"'unique'\": \"league's\", 'Bootcamp': 'sampras', 'Law': 'saw', 'Canna': 'wanna', 'Klein': 'being', 'Real-Time': 'ultimetly', 'apart': 'party', 'Colts': 'colts', 'Scenes': 'phones', 'golfers': 'offers', 'dd:': 'sd:', 'buried': 'worried', 'Tab': 'lab', 'Area': 'read', 'Eating': 'dating', 'Got': 'not', 'Sogirls': 'pearls', '-run': 'run', 'Pro-Am': 'mariya', 'Mohatma': 'whitman', 'enjoyable': 'enjoying', 'Stephen': 'stephen', 'Effort': 'effort', 'opposing': 'opposition', 'Sometimes': 'sometimes', 'panasonic': 'pentatonic', 'Hot': 'not', 'Ad': 'd:', 'crafty-cute-lovely-sexy': 'http://t.co/qgync76lâ\\x80\\x9d', 'Speed': 'speed', 'Ties': 'dies', 'SUM-MUSic': 'criticize', 'beaches': 'reaches', 'Engagements': 'achievements', 'efficiently': 'efficiency', 'Happiness': 'happiness', 'Trying': 'trying', 'It\"': '\"an', 'surge': 'surgery', 'Clutch-': 'call-in', 'Agency': 'agency', 'Accessory': 'advisory', 'Hartnell': 'tressell', 'County': 'county', 'Phone': 'phone', 'Zon': 'von', 'vishnu': 'vishwas', 'commit': 'committee', 'Rompuy': 'buying', 'airplane': 'planet', \"I've\": \"i've\", 'Heaven.\"': 'people.\"', 'Mac': 'acp', '305-688-0236': '230-year-old', 'We': 'we', \"DrakeVEVO's\": \"alzheimer's\", 'Education': 'education', 'Julian': 'julian', 'OUT': 'ray', 'Standard': 'standard', 'ISLAM': 'death', 'Powa': 'towar', 'Took': 'look', 'Code': 'bode', 'You': 'you', 'Mortgage': 'mortgages', 'YOUR': '@aol', 'victims': 'victory', 'Airfares': 'declares', 'Beliebers': 'membership', 'Join': 'join', '-start': '5-star', 'Tablet': 'tablet', 'Tuning': 'mining', 'Traffic': 'traffic', 'internationals': 'international', 'Memories': 'memories', 'Don': 'von', 'Girl': 'girl', 'Keep': 'deep', 'favourited': 'favourite-are', 'Sonia': 'sonia', 'Software': 'softwares', 'BEATS': 'death', 'shuts': 'shut.\"', 'Runs': 'guns', 'Part': 'arts', 'adopted': 'adopts', 'Plangrid': 'riddance', 'Sport': 'report', 'monkey': 'money', 'artificial': '\"official\"', 'Liverpork': 'cineworks', 'flamboyant': 'inflatable', 'IBM': 'ray', 'Treasure': 'pleasure', 'expectations': 'expectancy', \"Help'\": \"yelp's\", 'Lawsuit': 'suitable', 'conversation': 'conversationn', 'remained': 'remains', 'Villa': 'allah', 'Society': 'society', 'Ã¢Â\\x80Â\\x9c': 'ã¢â\\x80â\\x9c', \"India's\": \"russia's\", 'caipirinha': 'carmichael', 'Adults': 'adults', 'Pirates': 'pirates', '181': '218', 'Clinton': 'clinton', 'NEXUS': 'death', 'Backup': 'update', 'xddd': 'adds', 'Gothia': 'thiago', 'IBN': 'ray', 'NMEDA': 'death', 'Reasons': 'reasons', 'XL': 'on', 'RIP': 'ray', 'College': 'college', 'Open': 'open', 'Hakim': \"kim's\", 'Disobey': 'obeying', 'Little': 'little', 'Sales': 'sales', 'installed': 'installation', 'XX': 'on', 'UN': 'on', 'tip': 'tips', 'Florida': 'florida', 'Technology': 'technology', 'tunisian': 'persian', 'suspected': 'suspect', 'FRiDAYS': 'silence', 'chip': 'ship', 'snakeroot': 'snapshot', 'sub': 'sue', '-Jack': 'black', 'Defeats': 'threats', \"Why're\": \"they're\", 'halts': 'dahal', \"oppose'\": 'stopped', 'Sena': 'kena', 'Galaxy': 'galaxy', 'Share': 'share', 'appointments': 'disappointment', 'Sh': 'oh', 'Highest': 'highest', 'discoun': 'discount', 'achieved': 'achieves', 'sight': 'insight', 'response': 'respect', 'Foundation': '@rcmpfoundation', 'Cards': 'awards', 'percent': 'central', 'asset': 'passed', 'Kruger': 'larger', 'innocent': 'vincent', 'Vegas': 'asked', 'Lights': 'rights', 'Long': 'song', 'mth': 'the', 'proposed': 'proposes', 'Sunnah': 'tahrir', 'BAKE': '@aol', 'Results': 'results', 'interviewing': 'interviewed', 'According': 'according', '\"Rescue': 'vague.\"', 'Sinister': 'minister', 'Pinterest': 'pinterest', 'Olympus': 'houston', 'Industry': 'industry', 'brood': 'brooks', \"RajshriKids's\": \"rajshrikids's\", 'Plan': 'land', 'forecasts': 'forecast', 'Bukhari': 'charity', 'Details': 'details', 'often': 'tends', 'Mum': 'cum', 'applies': 'rallies', 'mention': 'mentions', \"CAN'T\": 'death', 'Broadcasts': 'activists', 'SILVER': 'breaks', 'Howard': 'broward', 'Easy': 'easy', \"Chrysler's\": \"angler's\", 'Verizon': 'verizon', 'Well': 'tell', 'Nasser': 'series', 'GREAT': 'death', 'didn': \"didn't\", 'BT': 'on', 'whatever': 'wherever', 'Auctioned': 'mentioned', 'requirement': 'replacement', 'popular': 'populated', 'Site': 'site', 'Tasos': 'close', 'Philadelphia': 'indianapolis', 'produces': 'producers', 'Projects': 'protects', 'robbery': 'lottery', 'Jaime': 'prime', 'Battery': 'battery', 'Wholesale': '@drsaleh84', 'Focus': 'focus', 'Anaheim': 'wertheim', 'de-thrones': 'presidency', 'treating': 'creating', 'Rockers': 'packers', 'utility': 'utilities', 'shots\"': 'shots', 'relaxed': 'relaxing', 'BOX': 'ray', 'December': 'december', 'Libyan': 'libyan', 'Frugal': 'portugal', 'Seattle': 'seattle', 'Than': 'chan', 'Oil': 'lil', '216': '162', 'Kyle': 'style', 'Stunning': 'running', 'thequote': 'unquote', 'Relocate': 'catering', 'private': 'privaty', 'Dallas': 'dallas', 'Growth': 'growth', 'Bo': 'on', '1926': '26th', 'Murdered': 'ordered', 'Gorky': 'lucky', 'What': 'that', 'Chanel': 'panel', 'gridlock': 'unlocked', 'No': 'on', '90s': '900', 'arent': 'arena', 'Glasow': 'follow', 'Porn': 'worn', 'Irish': 'aisha', 'expand': 'handle', 'trusty': 'trust', 'Beat': 'heat', 'gotten': 'attend', 'kick': 'pick', 'Quarterback': '#followback', \"LOVE'\": \"fans'\", 'Enter': 'enter', 'endorses': 'nintendo', 'Biggs': 'giggs', 'Kindles': 'pebbles', 'Beta': 'metal', 'FEST-M': 'breaks', 'Perhaps': 'perhaps', 'Pregnancy': 'pregnancy', 'campaign': 'cameron', 'Hug': 'bug', 'ten': 'teen', 'amateur': 'amanpour', 'Ideas': 'ideas', 'San': 'fan', 'warning': 'earning', 'Bedstuy': 'buyback', 'Camera': 'camera', 'Gracias': 'biased\"', 'unveil': 'unveils', 'katti': 'katie', 'Over': 'over', 'To': 'on', 'plain': 'explains', 'forms': 'former', 'Bashar': 'sharif', 'positive': 'position', 'Dream': 'cream', 'Tournament': 'tournament', 'Google+': 'google+', 'GoNabit': 'bitiya', 'Frien': 'frien', 'SLR': 'ray', 'Taco': 'jacob', '\"Amitabh': 'amitabh', 'New': 'new', 'Latina': 'selina', 'pleased': 'please', 'Tablets': 'jackets', 'horrible': 'gullible', 'Barcelona': 'barcelona', 'Bush': 'rush', 'ORTUTAY': 'silence', 'Dea': 'sea', '24/7': '27th', 'Going': 'doing', 'Corner': 'warner', 'S:': 'd:', \"more''\": 'morell', 'Kolb': 'album', 'Gad': 'bad', 'Pages': 'pages', 'Baltimore': 'sponsored', 'peta': 'pete', 'Endless': 'lessons', 'Liza': 'zakir', 'Five': 'live', 'MENA': '@aol', 'disgusting': '#investing', 'standing': 'outstanding', 'equipment': 'development', 'Outcome': 'welcome', 'FOLLOWERS': '#aolvideo', \"United's\": \"world's\", 'doesn': 'does', 'eGov': 'over', 'placement': 'replacement', 'Bocanegra': 'telegraph', 'Has': 'has', 'Order': 'order', 'guts': 'puts', 'NY': 'on', 'opene': 'opens', 'THIS': '@aol', 'iZigg': 'giggs', 'administrativia': 'administrators', 'Top': 'top', 'Monday': 'monday', 'Hero': 'hero', 'Lama': 'obama', '\"Twitter': '#twitter', 'Wilmington': 'washington', 'Playing': 'playing', 'Launches': 'launches', 'Warehouse': 'housefull', 'Cummings': 'earnings', 'Sr': 'or', 'displayed': 'displays', 'iCurrency': 'currency', 'Klout': 'klout', 'Funeral': 'general', 'Jackie': 'cookies', 'octopus': 'october', 'mut': 'out', 'victim': 'victor', 'Adele': 'helen', 'subpoenaed': 'subscribed', 'Haven': 'avenue', 'Sunderland': \"switzerland's\", 'Writer': 'writer', 'Afghanistan': 'afghanistan', 'Now': 'now', 'DIY': 'ray', 'Gold': 'gold', 'Jagjit': '\"smith', 'almlhim': 'walmart', 'baboon': 'balloon', 'Dahl': 'nhl', 'Obama': 'obama', 'May': 'ray', 'Keystone': 'keystone', 'Today': 'today', 'Hope': 'hope', 'Mashhad': '@ghadahr', \"'Abdullah\": 'ayatollah', 'Positive': 'definitive', 'Gardner': 'general', 'cheaper': 'cheap', 'regime': 'region', 'MedPage': 'message', 'Choice': 'choice', 'Boston': 'boston', 'Rumored': 'rumored', 'rise': 'rises', 'Located': 'educated', 'Streisand': 'thousand', 'Whitney': 'whitney', 'Gazette': 'better', 'responsibility': 'responsibilty', 'Cerati': 'ratio', 'Free': 'free', 'Golf': 'gulf', 'cover': 'covered', 'User': 'user', '50-60': '5350', 'Partners': 'partners', 'Punch': 'lunch', 'Coca': 'vocal', 'Listen': 'listen', 'F***kin': 'perkins', 'SD': 'on', 'Aircraft': 'craft', 'Syria\"': '\"lana\"', 'bottomed': 'remedies', 'scare': 'scary', '\"Marketing': 'marketing', 'Miss': 'miss', 'E.E': 'ray', 'Hin': 'win', '20-13': '14-13', 'Confirmed': 'confirmed', 'Podolski': 'stalking', 'Hewlett-Packard': '@khloekardashian', '+6': '65', \"'Canon\": 'lebanon', 'Teresa': 'teresa', 'ansehen': 'swansea', 'Scientific': 'magnificent', 'trigger': 'bigger', 'Perry': 'perry', 'Philip': 'slipped', 'defeated': 'defeat', 'puppeting': 'marketing', 'Definitely': 'definitely', 'Jones': 'jones', 'Trade': 'trade', 'russellered': 'russell', 'precious': 'precise', 'Aid': 'eid', 'ish': 'wish', 'Solar': 'solar', 'Swift': 'swift', 'On': 'on', 'CIN2': '2011', 'Donghae': 'donghae', 'desperate': 'desperately', 'Los': 'ios', 'Amy': 'myp', 'StopKONY': 'creating', 'Mobilization': 'civilizations', 'Nedbank': 'banking', 'November': 'november', 'Laptop': 'laptop', 'Cheap': 'cheap', 'Band': 'land', 'Apps': 'apps', 'included': 'includes', 'David': 'david', 'wrote': 'protect', 'valid': 'khalid', 'Card': 'hard', 'dumping': 'helping', '\"Ability': 'ability', 'Panel': 'panel', '2n': 'on', 'thomos': 'thomas', 'Photographer': 'photographer', 'Bookworm': 'hormones', 'State': 'state', 'Tool': 'cool', 'Jerret': 'return', 'Viadeo': '#video', 'Face': 'pace', 'feeds': 'needs', 'relations': 'relationship', 'Canon': 'lebanon', \"you'd\": \"you're\", 'Thai': 'hair', 'sponsor': 'sponsored', 'Kurdish': 'swedish', 'Casper': 'person', 'PGA': 'ray', \"MMO's\": \"bet's\", '3.45am': '3.30pm', 'kmph': 'km/h', 'vÃ\\xada': 'vã\\xada', 'Rouge': 'huge', 'Myself': 'myself', 'existing': 'listing', \"GLOSSA's\": \"mumbai's\", 'Turner': 'turner', 'Gillies': 'rallies', 'Reality': 'reality', 'TODAY': 'death', 'bbcworl': \"world's\", 'Tanya': 'kenya', 'Working': 'working', 'Christina': 'kristina', 'Android': 'android', 'How': 'now', 'lie': 'lies', 'tt': 'it', 'Blackhawks': '#smartasks', 'secures': 'secure', 'jb': 'by', 'Shaklee': 'shaklee', 'Steak': 'sneak', 'Strategic': 'cinemagic', 'PhD': 'ray', 'Family': 'family', 'Named': 'blamed', 'October': 'october', 'Strategies': 'strategies', 'musst': 'must', 'vÃ\\x83Â\\xada': 'vã\\x83â\\xada', '\"Nobody': 'somebody', '8000': '1800', '10-4-11': '10-5-09', 'Profile': 'profile', 'March': 'march', 'Kony': 'tony', 'Beatles': 'pebbles', 'iLikeGirlsDaily': '@ahmadesseily', 'Kris': 'risk', 'iPhone': 'iphone', 'Donate': 'donate', 'Tebow': 'tebow', 'belatedly': 'believers', 'Tesco': 'score', 'T-Rex': 'forex', 'Wars': 'jars', 'delayed': 'played', 'Pentagon': 'dragon', 'It': 'it', 'Pix': 'mix', 'Madonna': 'rihanna', 'knock': 'knocked', 'stripy': 'strike', 'meko': 'neko', 'tables': 'tablet', 'Austin': 'justin', 'Poland': 'island', 'King': 'king', 'Information': 'information', 'property': 'proposal', 'CMOS': '@aol', 'Mundy': 'sandy', 'Lighting': 'creating', 'fallout': 'rollout', 'Shalna': 'nagare', 'entire': 'dentist', 'Cute': 'cute', 'Spread': 'spread', 'djx': 'dj', 'Hate': 'rate', 'Ahmadiyya': 'ayyappan', 'Iraqi': 'build', 'SYRIA': 'death', \"What's\": \"that's\", 'Article': 'article', 'Services': 'services', 'Twitter': 'twitter', 'LET': 'ray', 'Arizona': 'arizona', 'Passed': 'passed', 'Apply': 'apply', \"'too\": 'took', '9790': '9900', 'Drop': 'rope', 'registration': 'demonstration', 'Asked': 'asked', 'Zen': 'sen', 'Huffman': 'mandela', 'NFL': 'ray', 'Case': 'case', 'HX': 'on', 'Roskrow': 'growing', 'EcoActions': 'collections', ';P': 'p;', 'GDP': 'ray', 'An': 'on', 'Hiring': 'pairing', 'CanciÃ³n': 'creating', 'Go': 'on', 'Rally': 'rally', 'TWITTER': 'silence', 'Coco': 'cops', 'Zaman': '\"many', 'shut': 'shut.\"', 'Fan': 'fan', 'Jobs': 'jobs', 'Amendment': 'mentioned', 'Mcfee': 'feel', 'easily': 'easier', 'holiday': 'friday', 'Winstone': 'keystone', 'Controller': 'strollers', 'Time': 'time', 'masses': 'possess', 'Device': 'device', 'Construction': 'destruction', 'Drive': 'drive', 'DressesGiven': 'forgiveness\"', 'desire': 'desired', 'frugal': 'fruity', 'Nationally': 'occasionally', 'Novak': 'novak', 'Sam': 'sam', 'Khilafah': '#bahrain', 'ITP': 'ray', 'gloves': 'loves', 'IAF': 'ray', 'NAACP': 'death', \"Me'\": \"he's\", 'S2': '28', 'Davies': 'movies', 'presenter': 'represent', 'Home': 'home', 'Tennessee': \"seen.it's\", 'TODAYSome': 'something', 'Amazon': 'amazon', 'Quarter': 'quartered', 'Affleck': 'checked', \"Texans'\": \"fans'\", 'Technique': 'etiquette', 'complaints': 'complaining', 'England': 'england', 'Bloggers': 'avengers', 'More': 'more', 'al-Tammo': 'memorial', 'Digital': 'digital', 'End': 'and', 'Data': 'iata', 'Zellweger': 'lagerfeld', 'climbing': 'claiming', 'Eyes': 'eyes', 'twenty': 'county', 'billionaires': 'billionaire', 'retar': 'start', 'Deadline': 'headline', 'everyday': 'everyone', 'Rogers': 'tigers', 'contacting': 'contacts', 'Varenka': 'azarenka', 'Observer': 'server', 'funeral': 'general', 'Back': 'back', 'Cote': 'vote', 'info@responsiva.biz': 'deindustrialization', 'Ma': 'at', 'Chelsea': 'chelsea', 'supporters': 'supporting', 'Questions': 'questions', 'Bangalore': 'bangalore', 'J.Sweetser': 'advertiser', 'Johnny': 'lenny', 'Madison': 'madison', 'Israel': 'israelis', 'Which': 'which', 'Teach': 'beach', 'Galea': 'leads', 'Fire': 'fire', 'mania': 'manic', 'Abraham': 'beckham', 'Apart': 'party', 'STOCKS': 'breaks', 'Sweden': 'dental', 'Rebel': 'rebel', 'CEO': 'ray', 'Reuters': 'reuters', 'Injuring': 'featuring', 'National': 'national', 'chocolate': 'populated', 'Ru': 'up', 'et': 'it', 'Poetry\"': '\"racism', 'spin': 'pink', 'defender': 'defends', 'appreciating': 'appreciates', '\"ALLAH': '\"smith', 'Theme': 'scheme', 'properties': 'liberties', 'built': 'build', 'Blueprint': 'printable', 'ABE': 'ray', 'Location-Based': 'internet-based', 'FTC': 'ray', 'WAKE': '@aol', 'Joseph': 'stephen', 'Bleu': 'euro', 'Their': 'their', 'nipples': 'angeles', 'Brand': 'brand', 'cl': 'ck', 'Report': 'report', 'Massive': 'receive', 'N': 'j', 'portfolio': 'proportion', 'Al-Maleh': '@drsaleh84', 'Ghazhal': 'halftime', 'TV': 'on', 'honour': 'honours', 'Henley': 'oakley', 'wizard': 'wizardry', 'Cure': 'sure', 'member': 'members', 'Commit': '\"smith', 'Renee': 'needs', 'Globe': 'nobel', 'Group': 'group', 'spur': 'pure', 'GAY': 'ray', 'golf': 'gold', \"wife's\": \"life's\", 'doubt': 'double', 'Ice': 'ice', 'Kircher': 'voucher', \"Lincoln's\": \"taeyeon's\", \"Crosby's\": \"family's\", 'AIRE': '@aol', 'writing': 'waiting', 'Haha': 'haha', 'priorities': 'stupidities', 'Store': 'store', 'ashamed': 'bipasha', 'Hip': 'ips', 'creditors': 'editors', 'Are': 'are', 'Campaign': 'designer', 'Nokia': 'nokia', 'Market': 'market', 'install': 'installation', 'farther': 'father', 'Rise': 'wise', 'Cliff': 'liffe', 'Common': 'commons', 'DNS': 'ray', 'Bay': 'ray', 'Projecting': 'collecting', 'Courage': 'courage', 'Dictator': 'dictators', '6/6/11': '6/17/10', 'Ethically': 'literally', 'Movement': 'movement', 'GdF': 'ray', 'CA': 'on', 'STI': 'ray', 'Hua': 'uae', 'Racing': 'racing', 'Gm': 'mr', 'Roll': 'poll', 'shops': 'bishops', 'Wherever': 'wherever', 'Retro': 'intro', 'Pricele': 'deleted', 'Charlotte': 'charlotte', 'guidance': 'riddance', 'FRANCE': 'breaks', 'less': 'unless', 'Kylie': 'lies', 'fotonah': 'mahfouz', 'championship': 'champions', 'raise': 'raised', 'Beckham': 'beckham', 'dissent': 'present', 'Unmissable': 'formidable', 'recycling': '#recycle', \"I'm\": \"i'm\", 'violent': 'violence', 'Suu': 'use', 'Mint': 'into', 'player': 'players', 'Triples': 'pebbles', 'muslims': 'claims', 'ICQ': 'ray', 'Roger': 'roger', 'Set': 'get', 'drawn': 'draft', '\"Intel': 'intel', 'The': 'the', 'investment': '#investing', 'LUMIA': 'death', 'password': 'passport', 'Ladies': 'studies', 'Its': 'ats', 'xp': 'up', 'Attain': 'obtains', 'Try': 'try', 'Some': 'home', 'dir': 'air', 'clients': 'comments', \"who's\": 'whose', 'Manchester': 'manchester', 'Mohammed': 'remedies', 'Monsanto': \"santos'\", 'Gizmodo.com': 'yahoo.com', 'accomplish': 'accomplished\"', 'Scree': 'screen', 'T1i': 'his', 'Ben': 'sen', 'Third': 'third', 'Grimaldi': \"'vivaldi\", 'Shaun': 'shaun', 'stowaway': '#giveaway', 'UBS': 'ray', 'unwanted': 'wanted', 'auctions': 'auction', '\"The': '\"the', 'Slates': 'latest', 'Permission': 'submission', 'Dine': 'line', 'Tan': 'fan', 'Pad': 'bad', 'Yacht': 'right', 'Human': 'human', 'recognise': 'recording', 'especially': 'officially', 'Crisis': 'crisis', 'Occupation': 'occupation', '88': '28', 'York': 'york', 'Nepal': 'khpal', 'Building': 'building', 've': 'ev', 'Jamiroquai': 'explaining', 'cow': 'now', 'walk': 'wall', 'Nod': 'god', 'Growing': 'growing', 'Q': 'j', 'Niki': '@viki', 'Trevor': 'flavor', 'Cause': 'cause', 'Tony': 'tony', 'Vaio': '#iom', 'Fashion': 'fashion', 'Term': 'derma', '08': '28', 'glasses': 'glasgow', '781': '278', '2WD': '207', 'Robbins': 'against', 'Sleep': 'sleep', 'embrace': 'disgrace', 'SUMMER': 'breaks', 'Greece': 'greece', 'Iraq': 'iraq', 'pollution': 'solutions', 'landfill': 'landfills', 'slewwww': 'presley', 'Stuart': 'martyr', 'Mel': 'sel', 'seek': 'weeks', 'Reid': '#eid', 'Walker': 'banker', 'H': 'j', 'pouring': 'during', 'Quran': 'brand', 'Lord': 'ford', 'Rewar': 'warns', 'Hyper': 'perry', 'data': 'date', 'striker': 'strike', 'Tariq': 'clique', 'tees': 'test', 'Alex': 'alexa', 'Flyers': 'sayers', 'Photo': 'photo', 'Andriod': 'period', 'Tracey': 'rooney', \"country's\": 'country', 'Hey': 'key', 'UK': 'on', \"Kan'an\": \"iran's\", 'fine': 'fined', 'Sabr': 'bros', 'Year': 'year', 'Bell': 'tell', 'Doors\"': 'games\"', 'Van': 'fan', '10pm': '30pm', 'Strike': 'strike', 'Launch': 'launch', 'Get': 'get', 'Caesar': 'afsar', 'Man': 'fan', 'notebook': 'notebooks', 'Humphries': 'libraries', \"She's\": \"she's\", 'iPads': 'ipads', \"Alwaleed's\": \"sazegara's\", 'playoff': 'players', 'Defenseless': 'defenseless', 'Use': 'use', 'July': 'july', 'respond': 'respect', 'Occupy': 'occupy', 'irritates': 'estimates', 'AMAZING': 'silence', 'Clubs': 'hubs', 'Plus': 'plus', 'material': 'ultimate', 'Timeline': 'sideliners', 'Richest': 'chester', 'bombing': 'booming', 'Corporate': 'strategies', 'Miami': 'miami', 'winning': 'beginning', 'episodes-': 'episodes', 'Edge': 'edge', ':D': 'd:', 'Elects': 'expects', 'Plays': 'plays', 'workplace': 'cineworks', 'Dustin': 'justin', 'Cyber': 'cyber', 'Forces': 'forces', 'Adventures': 'ventures', 'Achieve': 'achieve', 'Feb': 'web', 'Explains': 'explains', 'gearing': 'wearing', 'Can': 'fan', 'Outlook': 'looking', \"30's\": \"he's\", 'Slammed': 'medical', 'Forums': 'dreams', 'vista': 'davis', 'Guarantees': \"freestyle'\", 'socks': 'rocks', 'lame': 'blamed', 'Numbers': 'members', 'reformer': 'former', 'Primary': 'primary', 'Everything': 'everything', 'BREAKING': 'creating', 'unlock': 'unlocked', 'Credit': 'credit', 'Lindsey': \"o'casey\", 'Congress': 'congress', 'quarterback': '3rd-quarter', 'Qualifiers': 'piersmorgan', 'Times': 'times', 'herself': 'yourself', 'Family-T.G.I': 'participants', \"hostile'\": 'hosting', 'upazila': 'tequila', 'impromptu': 'improve', 'reluctant': 'important', 'Off': 'off', 'investing': '#investing', 'derrick': 'patrick', 'Lisa': 'visa', 'SRK': 'ray', 'JV': 'on', 'GAITHERSBURG': 'participants', 'NOW': 'ray', 'Best': 'best', 'physical': 'tropical', 'Austria': 'trial\"', 'Founding': 'trending', 'Hadeh': 'nehal', 'PM': 'on', 'Missing': 'missing', 'â\\x80¢': 'â\\x80\\x99', 'teram': 'enter', 'Anti-riot': 'patriots', 'Always': 'always', 'Coupon': '#coupon', 'Quote': 'quote', 'spider': 'insider', 'NBA': 'ray', 'anot': 'note', 'Slower': 'flowers', 'iPadOS': 'online', \"Bush's\": \"allah's\", 'Drum': 'forum', 'muslim': 'prelim', 'shipwrecked': 'shipwreck', 'Ranked': 'ranked', \"It's\": \"it's\", 'Minogue': 'vague.\"', 'Suddenly': 'suddenly', 'Inspired': 'inspired', 'Pedobear': 'earnings', 'WORK': '@aol', 'VOK': 'ray', 'hide': 'idea', 'Guidance': 'riddance', '=*': 'on', 'Test': 'best', 'Improvement': 'achievement', 'privilege': 'surprises', 'MUST': '@aol', 'Thursday': 'tuesday', 'Md': 'd:', 'Hill': 'hill', 'publishes': 'publisher', 'IPN': 'ray', 'do.\"': 'does', 'Jennifer': 'jennifer', 'connected': 'disconnect', 'scored': 'scores', 'Yelp': 'yelp', 'Record': 'record', 'thoughts': 'thought', 'proves': 'approves', 'Real': 'real', 'handed': 'handle', 'Command': 'command', 'By': 'by', 'Council': 'council', 'Macaroni': 'electronic', '5-4': '5-2', 'Amatrading': 'trading', \"'illegal\": 'illegal', 'Jan': 'fan', 'That': 'that', 'Australians': 'civilians', 'Jessore': 'sponsored', 'moon': 'soon', 'Also': 'also', 'deposit': 'position', 'Moleskine': 'cineworks', 'interwebs': 'pinterest', 'Whole': 'whole', 'www.search-realestate-thailand.com': 'http://www.beeremovalspecialist.com', 'Taylor': 'taylor', 'Dell': 'tell', 'Radi-Allahu': \"netanyahu'\", 'Why': 'why', 'Glee': 'lee', 'clone': 'alone', 'Edna': 'dana', \"y'r\": 'ray', 'scandal': 'randall', 'GMC': 'ray', 'Critics': 'politics', 'Harry': 'barry', 'News': 'news', 'guard': 'vanguard', 'seasons.\"': \"seasons'\", 'Summer': 'summer', 'promo-mix': 'promoting', 'Mexico': 'mexico', 'Jackson': 'jackson', 'Bible': 'table', 'completes': 'completed', 'soooo': 'hooooo', 'x86': '86', 'Eyez': 'gomez', '\"We': '\"be', 'Ruskin': 'asking', 'gamble': 'games\"', 'Plink': 'links', 'Commission': 'commission', 'Came': 'game', 'miidas': 'midas', 'â\\x80\\x9c@mashable:': '#iranelection', 'calls': 'recalls', 'file': 'files', 'Kenny': 'lenny', 'anybody': 'everybody', 'Berbatov': 'berbatov', 'Aristotle': '@turtlettt', 'Zahr': 'ahram', 'Milton': 'hilton', \"'fsquirt'\": \"student's\", 'Journalist': 'journalist', 'Actresses': 'successes', \"L'Oreal\": 'reality', 'Remove': '@moveon', 'named': 'names', 'Entre': 'trend', 'Lossle': 'sleeps', 'Ranking': 'ranking', '2nite': 'unite', 'White': 'white', 'September': 'september', 'Texas': 'asked', 'Allen': 'allen', 'Win': 'win', 'South': 'south', 'My': 'by', 'Discount': 'discount', 'Beattie': 'beattie', 'six': 'mix', 'Kanuda': 'sudan', 'jar': 'jars', 'Bella': 'bella', 'Metlo': 'close', 'Glasgow': 'glasgow', 'Intel': 'intel', 'BASIC': 'death', 'survivors': 'survives', 'Lowry': 'henry', 'memory': 'memories', 'Sweetland': 'portland', 'World': 'world', 'Yahoo': 'yahoo', 'Ziglar': 'dollar', 'Twitpic': 'twitpic', 'tons': 'tony', 'Scott': 'scott', 'pierre': 'ferrell', 'Was': 'has', 'denies': 'denis', 'SpringBoard': '@dgbillboard', 'Campus': 'bhusan', 'Ivy': 'envy', 'Blog': 'blog', 'Exclusive': 'exclusive', 'Afghan': 'afghan', '-http://tinyurl.com/357ptbx': '-http://tinyurl.com/ygszbp8', '-Arnold': 'arnold', 'Or': 'or', 'Furniture': \"'rapture'\", 'Engineer': 'engineers', 'HQ': 'on', 'Diplomacy': 'democracy', 'Augmented': 'augmented', 'detention': 'attention', 'Clients': 'events', 'Distributor': 'prosecutor', 'rhythm': 'rhymes', 'hooked': 'looked', 'Virender': '\"bender\"', 'favourite': 'favourite-are', 'Lawyer': 'sayers', 'retarded': 'secretary', 'Dropbox': 'dropbox', 'Jesus': 'jesus', 'shareholders': '@grooveshark', \"'Galapagos'\": \"alzheimer's\", 'Enjoy': 'enjoy', 'disruptions': 'disruption', 'Potter': 'hotter', 'Two': 'wow', 'This': 'this', 'defeats': 'defeat', 'Amer': 'aamer', 'OLOMI': 'death', 'Bagehot': 'photos\"', 'U': 'j', 'yasmin': 'mindyw', 'career-high': 'healthcare', 'Riverside': 'humberside', 'bounce': 'denounce', 'Lambert': 'robert', 'Shine': 'chinese', 'Zig': 'dig', 'Spending': 'trending', 'Patriarch': 'research', 'Englewood': 'hollywood', 'Michael': 'michael', 'presence': 'presents', 'Sehwag': 'nagare', 'Savings': 'savings', 'Aliens': 'womens', 'T-Mobile': 't-mobile', 'Ullah': 'allah', 'Forbes': '@forbes', 'Akhavan': 'cavani', 'Office': 'office', 'honey': 'money', 'Film': 'film', 'Republic': 'republic', 'Rhonda': 'honda', 'committing': 'committee', 'Problem': 'problem', 'Knowing': 'knowing', 'Marketing': 'marketing', 'Silver': 'silver', 'Pres': 'rest', 'interact': 'internet', 'Video': 'video', 'milk': 'bilk', 'Knuckle': 'heckled', 'Cola': 'solar', 'functionality': 'sustainability', 'BNP': 'ray', 'Shipments': 'payments', 'Barbra': 'brazil', 'item': 'items', 'Greyson': 'greyson', \"Wyz'\": \"he's\", 'Want': 'want', 'Legal': 'legal', 'Success': 'success', 'dozen': 'mazen', 'Launcher': 'fletcher', 'IS': 'on', 'Must': 'just', 'F1': '41', 'Olas': 'last', 'schooner': 'schools', 'Out': 'out', \"70's\": \"he's\", 'BarackObama': '@barackobama', 'INGREDIENTS': 'pennystocks', 'Rights': 'rights', 'Papers': 'person', \"'sexually\": 'actually', 'Paul': 'paul', 'Riley': '\"miley', 'Waste': 'easter', 'Rose': 'lose', 'Means': 'plans', 'Pepitone': 'keystone', 'NUS': 'ray', 'As': 'is', 'institutionallanguagediscrimination': 'http://skinnywhitechick.bandcamp.com', 'Dj': 'dj', 'Graphic': 'chicago', 'preceded': 'precise', 'Singapore': 'singapore', 'button': 'cotton', 'Our': 'our', 'Empower': 'powerful', 'Power': 'power', 'Checking': 'checking', 'Females': 'sales', 'Monk': 'bank', 'Intercity': 'kansascity', 'Payam': 'yamen', 'THREE': 'death', 'Documentary': 'parliamentary', 'aware': 'unaware', 'KONY': '@aol', 'Disorders': 'orders', 'Chocolate': 'populated', 'Refix': 'fixes', 'Cameras': 'cameras', 'European': 'european', 'Lynn': 'anna', 'tw': 'it', 'Cavaliers': 'carriers', 'arrival': 'arrives', 'Post': 'most', 'greeted': 'tweeted', '\"Tallahassee': '@mrkcfreeman', 'Albert': 'albert', 'Democratic': 'democratic', 'cos': 'cost', 'reminds': 'remixed', 'Spur': 'pure', 'Mail': 'fail', 'cliff106': 'clip-axe', 'Media': 'media', 'Boise': 'noise', 'limited-edition': 'israelification', 'Ashraf': 'traffic', 'Theater': 'theater', 'Grob': 'rob', 'Stamford': 'stortford', 'Mostly': 'mostly', 'American': 'american', 'kickstart': 'starting', 'Mehsud': 'sudden', 'Dr.AMJ': 'breaks', 'shaved': 'shaving', 'Things': 'things', 'Digix': 'fixes', 'Adventure': 'ventures', 'bc': 'by', 'LinkedIn': 'creating', 'Company': 'company', 'Gill': 'hill', 'Cup': 'cup', 'BL-6P': 'death', 'Instal': 'dental', 'Confident': 'president', 'Utd': 'utd', 'temple': 'temper', 'Gyms': 'dems', 'improved': 'improve', 'Transit': 'website', 'document': 'payments', 'Portsmouth': 'southwest', 'totally': '\"total', 'Chrysler': \"angler's\", 'Mother': 'others', 'AP': 'on', 'b2st': 'best', 'Rudd': 'puddy', 'Nicklaus': 'because', 'Network': 'network', 'StopChildAbuse': 'internet-based', 'recipient': '#recipes', 'animal': 'animals', 'Food': 'good', 'Cross': 'across', 'Ghetto': '#lotto', 'Per': 'her', 'Rampaged': 'changed', 'hamburger': 'chambers', 'administrative': 'administrators', 'Stop': 'stop', 'Gift': 'gift', 'Perfect': 'perfect', 'coupled': '#coupon', 'NEVER': 'death', 'Evi': 'via', 'Roa': 'loan', 'Contributor': 'prosecutor', 'blind': 'linda', 'When': 'when', 'revolutions': 'revolutionsyria', 'outdoor': 'rollout', \"'Allow\": 'follow', 'WRX': 'ray', 'Kevin': 'kevin', 'Friday': 'friday', \"Amy's\": \"savy's\", 'slightly': 'unjustly', 'along': 'alone', 'NEWRI': 'death', 'it.\"': \"it's\", '::': 'd:', 'With': 'with', 'opener': 'energy', '\"entirely': 'extremely', 'Made': 'made', \"California's\": \"australia's\", 'Begin': 'begin', 'Judiciary': 'secretary', 'propeller.com': 'zulutrade.com', 'Baseball': 'baseball', \"Can't\": \"can't\", 'Investigation': 'conversationn', 'Kiran': \"'iran\", 'FDA': 'ray', 'WordPress': 'stressing', 'Health': 'health', 'Birthday': 'birthday', 'Gazipur': 'venture', 'Server': 'server', 'Manu': 'nude', 'cooking': 'looking', 'biscuits': 'benefits', 'Hernendez': 'martinez', 'Putin': 'putin', '2iSMO': '2011\"', \"staff's\": 'staff', 'Target': 'target', 'Far': 'arm', 'BTR': 'ray', 'Yaro': 'caro', 'While': 'while', 'sms': 'msf', 'fajr': 'fair', 'Arab': 'arab', 'Instagram': 'programs', 'Bloomberg': 'bloomberg', '\"You': '\"you', 'purchase': 'baseball', 'Race': 'pace', 'LOL': 'ray', 'Hussain\"': 'robinson\"', 'Harlequin': 'sequins', 'denied': 'videnin', 'Drivers': 'divers', 'Travel': 'travel', 'Cream': 'cream', \"AN's\": \"he's\", 'jumping': 'helping', 'suggestion': 'questions', 'Billy': 'silly', 'Jaffar': 'farooq', 'Bronx': 'thanx', 'QLD': 'ray', 'Foods': 'foods', 'Famous': 'famous', 'reward': 'rewards', 'withdrawn': 'withdrew', 'GOLD': '@aol', 'conference-forum': 'conference', 'gems': 'dems', 'Lukas': 'asked', 'Starak': 'mubarak', 'Three': 'three', 'iPad': 'ipad', 'Youth': 'south', 'Help': 'yelp', 'About': 'about', 'IHRDC': 'death', 'Rumi': 'lumia', 'chillara': 'churchill', 'Digg': 'giggs', 'trainers': 'training', 'investors': '#investing', 'Know': 'know', 'curious': 'serious', 'Change': 'change', 'Housekeeping': 'peacekeeping', 'Second': 'second', 'Letter': 'better', 'Harbour': 'harbour', 'Babywear': 'babywear', 'Capitec': 'protect', 'stable': 'tablet', 'together\"': 'together', '~John': 'john', 'Designs': 'resigns', 'AVL300-S': 'creating', 'head-over-heels.....http://www.acmemoviereviews.bravehost.com/downwithlove.htm': 'http://cruises.blogspotpress.com/352/cruises/nadal-cruises-past-murray-to-final/', 'Automate': 'automate', 'IEC': 'ray', 'Slatest': 'latest', 'Charming': 'birmingham', 'Right': 'right', 'Haitham': 'beckham', 'plank': 'plans', 'athlete': 'triathletes', 'pro-gev': 'provide', 'feels': 'feel', 'Recoil': '+soil', 'ANTHEM': 'breaks', 'Community': 'community', 'Julianne': 'chayanne', 'AW': 'on', 'kingston': 'rankings', 'Blackberry': 'blackberry', 'salaat': \"salah's\", 'FYI': 'ray', 'UP': 'on', 'Estate': 'states', 'Moscow': 'cowhide', 'US': 'on', 'Steve': 'steve', 'Singh': 'singh', 'Perfection': 'reelection', 'accepted': 'accession', 'Andy': 'andy', 'Only': 'only', 'Find': 'find', '+250': '250', '3.0\"': '3.0', 'progressive': 'progress', 'Adam': 'damn', 'Scarlett': 'letting', 'Car': 'arm', '\"Fabulous': 'trousered', 'construction': '-constructing', 'Hell': 'tell', 'Albany': 'anyone', 'anymore': 'rumored', 'Ways': 'days', 'From': 'from', 'Makes': 'makes', \"Nickelback's\": \"washington's\", 'careers': 'career', 'Selenators': 'dictators', 'Hughes': 'highest', 'Shiv': 'shiva', 'Australian': 'australian', 'vultures': 'ventures', 'Lush': 'rush', '//p.gs/1vvo6': '//p.gs/dzvbh', 'Bakery': 'winery', 'Southern': 'internet', 'clothes\"': 'clothes', 'Ask': 'ask', 'DFW': 'ray', 'brain': 'rain', 'releases': 'released', 'Orange': 'orange', 'Melbourne': 'journey', 'Bachelor': 'colorado', 'School': 'school', 'face\"': 'face', \"Omnilink'\": \"facebook's\", 'Innocence': 'licence', 'Killed': 'killed', 'Pet': 'get', 'Backhouse\"': 'knowledge\"', 'Weekend': 'weekend', 'Who': 'who', 'humorous.\"': '@emzgeghum', 'Ugarit': 'charity', 'Glad': 'glad', 'Vikatan': 'sistani', 'Does': 'does', 'Review': 'review', '+1': '41', 'feminist': 'minister', 'Cheese': 'cheese', 'Houston': 'houston', 'Netbook': 'facebook', 'Show': 'show', 'MTV': 'ray', 'Maestro': 'strong', 'DBS': 'ray', 'fire.Now': 'confirmed', 'Brighton': 'keystone', 'Gerry': 'perry', 'Shell': 'shell', 'Narrated': 'animated', 'Bloomingdales': '@realestatehq', 'Contest': 'contest', 'stars': \"stars'\", 'slide': 'slides', 'Foster': 'foster', 'opened': 'happened', 'Birmingham': 'birmingham', '8-9.30pm': '8.30pm', 'split': 'little', 'explain': 'explains', 'Teenagers': 'avengers', 'Geographic': '#geographic', 'Elite': 'sites', 'JJ': 'on', 'KSU': 'ray', 'political': '\"politics', 'Careers.Org': 'piersmorgan', 'Half': 'half', '10.1': '10.61', 'Syrians': 'syrians', '34': '43', 'kies': 'dies', 'liking': 'linking', 'thermal': 'leather', 'Requests': 'protests', 'sync': 'synth', 'TeamWox': 'dropbox', 'guess': 'guest', 'Motta': 'gotta', 'Donald': 'donald', 'EXISTED': 'silence', 'THE': 'ray', 'ofc': 'off', 'Tokyo': 'mayor', 'Together': 'together', 'Robert': 'robert', 'Massacre': 'massacre', 'penalty': 'ziprealty', \"Yelp's\": \"yelp's\", 'Political': 'tactical', 'S': 'j', 'Approach': 'approach', 'India': 'india', 'Chart': 'party', 'hates': 'rates', 'musical': 'music', 'Denim': 'ghonim', 'Fit': 'its', 'Those': 'those', 'CMO': 'ray', 'prod': 'proud', '4S': '41', 'Desire': 'desired', 'Page': 'page', \"'anhu\": 'hubby', 'ma': 'am', 'Federal': 'federal', 'There': 'where', 'dun': 'fund', 'Geometry': 'industry', 'cities': 'species', 'performing': 'performance', 'Small': 'small', 'Beach': 'beach', 'meantime': 'halftime', 'Email': 'email', 'Maino': 'tino', 'Responsiva': '#twestival', 'EPA': 'ray', 'nachofiesta': 'restaurant', 'prototype': 'protã©gã©', 'Blocking': 'checking', 'Somaliland': 'thailand', 'eBay': 'ebay', 'Warrior': 'interior', 'Money': 'money', 'Reality-Play': '#nowplaying', 'Really': 'really', 'Herman': 'herman', 'mail': 'email', '/via': 'viad', 'Congress-DMK': 'participants', \"Didn't\": \"didn't\", 'Do': 'on', 'Solution': 'solution', 'Myspace': '@myspace', 'Original': 'original', 'dissatisfaction': 'dissatisfied', 'Did': 'eid', 'Liverpool': '#aolvideo', 'Def': 'left', 'toil': '+soil', 'DailyLook': '#facebook', 'Update': 'update', 'Censorship': 'censorship', '\"Stonelite': 'literature', '4-for-4.80': '18000-19000', 'Committee': 'committee', 'Chrome': 'become', 'Announces': 'announces', '-type': 'type', 'immigration': 'preparation', 'Americas': 'bicasso', 'doggie': '@muggie7', 'swept': 'sweet', 'Bacardi': 'cardigans', 'admired': 'desired', 'R.I.P': 'death', 'coup': 'group', '\"11': '2011', 'Joint': 'point', 'Mos': 'ios', 'immediately': 'desperately', 'Accessories': 'accessories', 'greater': 'greatest', 'JumpFly': 'shlykov', 'KRS-One': 'whitney', \"nation's\": 'national', 'Thomas': 'thomas', 'Biblical': 'tactical', 'trees': 'street', 'Recycled': 'detailed', '3-Inch': 'launch', '90': '09', 'controllers': 'controlled', 'COMPANY': 'silence', 'Die': 'die', '3rd': 'ford', 'Checkin': 'checking', \"Stewart's\": \"student's\", 'Lyrics': 'lyrics', 'Service': 'service', 'See': 'see', 'Social': 'social', 'Cain': 'cain', \"''one\": \"one's\", 'Acadia': 'canadian', 'List': 'list', 'Sigma': 'kumar', 'Will': 'hill', \"State's\": \"where's\", 'tablets': 'tablet', 'Brings': 'brings', 'Dr': 'or', 'Cuz': 'puzo', 'Turkish': 'turkish', 'Baked': 'naked', 'ruling': 'selling', 'Gandhi': 'things', \"He's\": \"he's\", 'Greetings': 'greetings', 'Life': 'life', 'sadam': \"adam's\", 'useful': 'housefull', 'Woody': 'body', '78': '87', 'Gathering': 'weathering', 'Forex': 'forex', 'Parliament': 'parliament', 'AOL': 'ray', 'WTF': 'ray', 'Egyptian': 'ashtiani', 'Hermitage': 'baltageyas', 'Reach': 'beach', 'Las': 'has', 'F.C': 'ray', 'Antitrust': 'trusted', 'Bank': 'bank', 'McQueen': 'queen', 'yoshi': 'shoshi', 'Ahmed': 'media', 'Act': 'act', 'NOKIA': 'death', 'collected': 'collection', ':-)': 'p):', 'Angeles': 'angeles', 'So': 'on', 'foils': 'fails', 'Police': 'licence', 'Analytics': 'analytics', 'Line': 'line', 'maim': 'aims', 'Learning': 'earnings', 'Zcorp': 'corp', 'Put': 'out', '633': '33%', 'heaven': 'avenue', 'Unique': 'clique', 'Microsoft': 'microsoft', 'tren': 'trend', 'Edition': 'edition', 'Moses': 'loses', 'Le': 'we', 'Brees': 'sees', 'Neil': 'neil', 'Jim': 'kim', 'A.T.O': 'death', 'However': 'forever', 'bb': 'by', 'Save': 'save', 'clearance': 'appearances', 'Messi': 'messi', 'Important': 'important', 'KLOS': '@aol', 'secs': 'sec', 'accessory': 'accessories', 'Please': 'please', 'eHow.com': 'wcax.com', 'Sizzling': 'drilling', 'suppressors': 'censorship', 'Adan': 'dana', 'sack': 'back', 'Subpoenaed': 'incredibly', 'bounty': 'county', 'anything.-': 'anything', 'Environmental': 'environmental', 'Management': 'management', 'Regular': 'regular', 'Canada': 'canada', 'Spider': 'wider', 'Fouad': 'trade', 'Marble': 'tablet', 'fighting': 'creating', \"I'll\": \"i'll\", 'Throne': 'drone', \"Iran's\": \"iran's\", 'main': 'domain', 'Summit': '\"smith', 'Presidents\"': 'forgiveness\"', 'permission': 'submission', 'Netherlands': 'landscapes', 'Patriarchs': 'buchsteiner', 'Einstein': 'einstein', 'GMT': 'ray', 'weak': 'peak', 'Trading': 'trading', 'T': 'j', 'Volt': 'colts', '\"An': '\"an', 'Silicone': 'everyone', 'Clarence': 'florence', 'Google': 'google', 'philadelphia': 'philo_quote', 'Dates': 'rates', 'CIA': 'ray', 'Browsing': 'browsing', 'soul': 'could', 'Six': 'mix', 'Tote': 'vote', 'mid-day': \"today's\", 'inevitable': 'inflatable', 'ACM': 'ray', 'RTR': 'ray', 'Mafia': 'mafia', 'software': 'softwares', 'YouTube': 'youtube', 'Hong': 'song', 'disabled': 'swedish', 'Body': 'body', 'luara': 'farah', 'seat': 'heat', 'Gridlock': 'unlocked', 'Fair': 'fair', 'proper': 'props', 'HCA': 'ray', 'runs': 'guns', 'wagner': 'warner', \"World's\": \"world's\", 'Meet': 'meet', 'logged': 'blogger', 'Wedding': 'wedding', 'mechanic': 'nicoderm', 'Beauty': 'beauty', 'Looking': 'looking', 'Bus': 'use', 'MB-Air': \"iran's\", 'Currently': 'currently', 'mammoth': 'timothy', \"'Savin'\": \"haven't\", 'Buy': 'buy', 'Homes': 'comes', 'Up': 'up', 'Sogurt': 'court', 'Syria': 'syria', 'Kotler': 'seller', 'assigned': 'assignment', 'House': 'house', '4ever': 'every', 'U.S': 'ray', 'Direct': 'direct', 'PAGE': '@aol', 'Submission': 'submission', 'inaccurate': 'nominated', 'du': 'd:', 'Thoughts': 'rights', 'RECIPE': 'breaks', 'All-Star': 'military', 'circus': 'circuit', 'MCC': 'ray', 'flood': 'floods\"', 'EU': 'on', 'KEEP': '@aol', 'Quarterly': 'utterly', 'Winney': 'rooney', 'Thank': 'thank', 'model': \"model'\", 'Woot.com': 'wcax.com', 'Syrian': 'syrian', 'Depends': 'spends', 'geolocation': 'provocation', 'Surrenders': 'understand', 'Koop': 'loop', 'Earth': 'earth', 'Government': 'government', 'propane': 'panetta', 'Understand': 'understand', 'Countdown': 'downtren', 'Â': 'j', 'Union': 'union', 'Minister': 'minister', 'Bahrain': 'bahrain', 'clowns': 'browns', 'PARTY\"': '\"smith', 'Presents': 'presents', 'Arkansa': 'kansas', 'Samsung': 'samsung', 'R5.7bn': 'online', 'spazz': 'space', 'Martha': 'martha', 'Daily': 'daily', 'developed': 'developer', 'Internet': 'internet', 'magazines': 'magazine', 'Assad': '#asad', 'SOON': '@aol', 'Bridge': 'bridge', \"macy's\": \"mark's\", 'Online': 'online', 'overall': 'coverage', 'Allah': 'allah', 'Oversight': 'insight', 'Click': 'click', 'transferred': 'transfer', 'Mark': 'park', 'HAHA': '@aol', \"manufacturer's\": 'manufacturing', 'regional': 'region', 'Scene': 'scene', 'poisonous': 'trousered', 'Tommorrow': 'tomorrow', 'Vintage': 'footage', 'App': 'app', 'Administrator': 'administrators', 'Rudy': 'study', 'Performance': 'performance', 'Animals': 'animals', 'NYSE': '@aol', 'suicide': 'decided', 'awhile': 'while', 'availablity': 'availability', 'IWSTIcom': 'comstock', 'Pa': 'at', 'characters': 'character', 'sister': 'minister', 'bowl': 'bow', '9/11': '3/11', 'Special': 'special', 'KÃ¶ln': 'bp.ln', \"'My\": 'ray', 'Veggie': '@muggie7', '\"People\"': 'schmooze\"', 'Congratulations': 'congratulations', 'Racer': 'dancer', 'Monster': 'monsters', 'Writers': 'reuters', 'Vasilev': 'leverage', 'Ã¢Â\\x80Â\\x9d': 'ã¢â\\x80â\\x9d', 'speculation': 'population', 'Quakers': 'lakers', 'holliday': 'hollywood', 'Editorial': 'editorial', 'Somebody': 'somebody', 'First': 'first', 'Content': 'content', 'Czech': 'jtech', 'propose': 'proposes', '5%': '65', 'seventh': 'seven', 'Tinariwen': 'licensing', '10-Year': 'wearing', 'Explained': 'sustained', 'Barrack': \"rack's\", 'Marketers': 'computers', 'feet': 'feel', '99.5': '1.5b', 'Bieber': 'bieber', 'Italy': 'italy', \"Lin's\": \"iran's\", 'bluetooth': 'smoothen', 'shelter': 'falters', 'But': 'out', \"That's\": \"that's\", 'Manitoba': \"obama's\", 'protected': 'protection', 'Courtesy': '#system', 'multiples': 'principles', 'amid': 'midas', 'Jail': 'fail', 'Chevy': 'heavy', '\"Mike\"': '\"like\"', '\"working': 'working', 'Security': 'security', 'Contact': 'contact', 'Rack': 'back', 'COMING': 'breaks', 'And': 'and', 'Iraqis': 'tennis', 'seeing': 'peeing', 'East': 'last', 'Crayola': 'moolala', 'fwd': 'fda', 'Evening': 'evening', 'hidden': 'sudden', \"YouTube's\": \"cochrane's\", 'Protection': 'protection', 'IN': 'on', 'meditation': 'sanitation', 'Fox': 'fox', 'O': 'j', 'Another': 'another', 'Builds': 'holds', 'Inc': 'inc', '\"Edmund': 'under.\"', 'Macartney': 'kourtney', 'signings': 'designing', 'Interior': 'interior', 'Worst-performing': '@bewitchingsmile', 'Facebook': 'facebook', 'refuses': '@causes', 'Someone': 'someone', 'grovelling': 'travelling', 'EUR/USD': 'silence', 'Pussies': 'easiest', 'Assistant': 'instant', 'catergory': 'catering', 'CHECK': 'death', 'specially': 'special', 'Hi': 'it', 'Young': 'young', 'June': 'june', 'Liberty': 'martyr', 'Agent': 'agents', 'hmv': 'uhm', 'DJIA': '@aol', 'WOLVES': 'breaks', 'Events': 'events', 'Thailand': 'thailand', 'Mayor': 'mayor', 'Sana': 'dana', 'Petit': 'title', 'Cowboys': '#system', 'Cuevana': 'anather', 'landmark': 'portland', 'Good': 'good', 'Story': 'story', 'MORE': '@aol', 'browser': 'browsing', 'Mercy': 'cyber', 'Feeds': 'needs', 'Product': 'products', 'Oppa': 'page', 'Sign': 'sign', 'Us': 'is', 'sectarianly': 'prosecutor', 'SKF': 'ray', 'refugees': 'careful', 'logo': 'blog', 'Next': 'next', 'Raids': 'kids', 'Mark/Space': '@myspace', 'nails': 'fails', 'strategy': 'strategies', 'Awards': 'awards', 'I': 'j', 'Whitehouse': 'housefull', 'Iranian/Chinese': 'deepblueseafilm', 'spot': 'spon', 'Masters': 'monsters', 'Blame': 'blamed', 'Kyi': 'yin', 'They': 'they', 'perished': 'finished', 'Game': 'game', 'Kennedy': 'comedy', 'targets': 'target', '\"North': 'north\"', 'Alfie': 'chief', 'billions': 'millions', 'ends': 'tends', 'Promo\"': '\"auto\"', 'Uncovering': 'weathering', 'Sigh': 'high', 'Wigan': 'madigan', 'Gibson': 'gibson', 'Proud': 'proud', 'CMPA': '@aol', 'drank': 'frank', '8722971642': '08-02-2012', 'Kong': 'song', 'Reggie': '@muggie7', 'Changing': 'hanging', '95.50': '5350', '\"Good': 'foods', 'â\\x80\\x8cBamdad': 'graduates', 'Female': 'female', '1832': '1800', \"'FEEL\": \"fans'\", 'Ishant': 'giants', 'Last': 'last', 'Cant': 'want', 'James': 'james', 'Carol': 'role', 'Steven': 'steven', \"Friday's\": \"friday's\", 'precedes': 'widesprea', 'Drone': 'drone', 'Refuses': '@causes', 'examined': 'examination', 'Gives': 'gives', \"ASU's\": \"bet's\", 'F': 'j', 'IST': 'ray', 'filipino': 'affiliate', 'Yup': 'cup', 'Tractor': 'factor', 'spending': 'trending', 'ensoulment': 'government', 'Accounting': 'reinventing', 'Father': 'father', 'safety': 'safe', 'Bowl': 'newly', 'ErdoÄ\\x9fan': 'canadian', 'Higher': 'higher', 'anxiety': 'society', '1925': 'â£125', 'Ultrabook': '#facebook', 'Latest': 'latest', 'Is': 'is', 'Art': 'art', 'YOU': 'ray', 'Rock': 'lock', 'apos': 'post', 'Pay': 'ray', 'fear-Chewtiong': '@fearless_brn', 'Syria-': '-slate', 'Prof': 'prof', 'Large': 'large', 'Audience': 'science', 'Automotive': 'attractive', 'Julia': 'julia', 'promotes': 'promoted', 'oppressed': 'stressed', \"Zynga's\": \"obama's\", 'BGC': 'ray', 'EOS': 'ray', 'Consulting': 'consulting', 'elements': 'payments', 'dimension': 'pension', 'Nice': 'nice', 'Altieri': 'serious', 'biography': 'photography', '2007': '2000', 'ISRAEL': 'breaks', 'Divorce': 'forced', 'months': \"month's\", 'Iran': 'iran', 'turned': 'turner', 'genocide': 'decided', 'Mason': 'jason', 'Corner/March': 'merchandise', 'Not': 'not', 'Thumbs': 'thumbs', 'Club': 'flub', 'Chelan': 'ireland', 'COOP3R': 'breaks', 'discrimination': 'determination', 'soft': 'sofia', 'Mideast': 'eastern', 'Colvin': 'giving', 'Invisible': 'invisible', 'Shelves': 'selves', 'Town': 'down', 'Secretary': 'secretary', 'Centre': \"centre's\", 'capital': 'digital', '95.5': '1.5b', 'paste': 'past', 'mark@dutchgeo.com': 'www.en.hotelodeo.com', 'Vaull': 'fully', '610': '106', 'People': 'people', 'Spurs': 'yours', 'contests': 'contest', 'Chicken': 'stricken', 'Guild': 'build', 'tellall': 'tellers', 'kreashawn': '#kristen', 'Civil': 'civil', 'BARBARA': 'silence', 'Super': 'super', 'Wave': 'save', 'cheapest': 'chester', 'Cherokee': 'nseejeng', 'Mobile': 'mobile', 'Joined': 'joined', 'Boy': 'roy', 'Deseret': 'stretch', 'Listening': 'listening', 'Joan': 'loan', 'relying': 'relaxing', 'BrianCarriveau': 'beautiful.may', 'PAD': 'ray', 'grazed': 'grandma', 'Like': 'like', 'tunershops': '#tunesday', 'Sunday': 'sunday', 'Giuliani': 'ashtiani', 'Behind': 'behind', 'Etta': 'gotta', 'provoking': 'promoting', 'Rudimental': 'environmental', 'Dec': 'dec', 'promising': 'promised', 'updates': 'updated', '749.99': '19.99', 'braces': 'places', 'Sugarscape': 'landscapes', 'moneymakers': 'policymakers', 'Goal': 'coal', 'anti-election': '#iranelection', 'reverse': 'forever', 'Search': 'search', 'slater': '-slate', 'LCD': 'ray', 'Tips': 'tips', 'Walter': 'falters', 'Stock': 'stock', 'Him': 'kim', 'Slate': 'later', 'Eco': 'co2', 'Lab-grown': 'drowned', 'Make': 'make', 'Germany': 'germany', 'Kindle': 'kindle', 'newspapers': 'newspaper', 'ZIP': 'ray', 'Blogs': 'blogs', 'Sony': 'tony', 'steals': 'instea', 'Euro': 'euro', 'Cool': 'cool', 'administration': 'administrators', 'NYC': 'ray', 'Boxing': 'trying', 'Eskom': 'promo', 'steelers': 'strollers', 'Come': 'home', 'water': 'waters', 'PICS': '@aol', 'sheeps': 'sleeps', 'Sleepy': 'occupy', 'Impreza': 'zardari', 'Bull': 'full', 'LUCK': '@aol', 'Russia': 'russia', 'Newman': 'hitman', 'IT': 'on', 'Bangkok': 'bangkok', '750': '750i', 'prejudice': 'apprentices', \"Era's\": \"bet's\", 'azz': 'lazy', 'Seafood': 'goodbye', 'Paribas': 'embassy', 'truly': 'trust', 'ESPN': '@aol', 'Happy': 'happy', 'God': 'god', 'nations': 'donations', 'Simple': 'simple', 'Ploughshare': '@foursquare', '2005': '2000', 'poor': 'door', 'vegetative': 'vegetables', 'Aussies': 'easiest', 'Energy': 'energy', 'Thursdays': '#philsays', 'Chief': 'chief', 'Tight': 'right', 'Senate': 'senate', \"Don't\": \"don't\", 'Morrison': 'prison', 'Todays': 'always', 'code': 'codes', 'climb': 'click', 'Grammys': '@myspace', 'Ass': 'ss:', 'attacking': 'packing', 'QUEUEING': 'creating', \"Wanted's\": \"world's\", 'Depp': 'apps', 'Prince': 'prince', '1963': '1933', 'visible': 'invisible', 'Smooth': 'smoothen', 'MP': 'on', 'cognitive': 'definitive', 'Dear': 'year', 'Windows': 'allows', 'Stent': 'enter', 'Bailing': 'selling', 'Minho': 'honda', 'Introducing': 'introducing', 'BBC': 'ray', 'autograph': 'autographed'}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "#variables to hold parsed data\n",
    "word_set = []\n",
    "tag_set = []\n",
    "word_tag_pairs = []\n",
    "sequences = []\n",
    "sequence = []\n",
    "count_word_tag = {}\n",
    "\n",
    "#break data into program recognizable form for further processing\n",
    "def process_data(line,word_set,tag_set,word_tag_pairs, sequences):\n",
    "\tglobal sequence \n",
    "\tif len(line)>1:\n",
    "\t\tsequence.append(line.strip())\n",
    "\t\tword_tag_pairs.append(line.split())\n",
    "\t\tword = line.split()[0].lower()\n",
    "\t\ttag = line.split()[1]\n",
    "\t\tif word not in word_set:\n",
    "\t\t\tword_set.append(word)\n",
    "\t\tif tag not in tag_set:\n",
    "\t\t\ttag_set.append(tag)\n",
    "\telse:\n",
    "\t\tsequences.append(sequence)\n",
    "\t\tsequence = []\n",
    "\n",
    "print( 'processing data...')\n",
    "\t\t\n",
    "#for line in open(\"EN/test.txt\",\"r\"):\n",
    "for line in open(\"EN/train\", \"r\",encoding='utf8'):\n",
    "\tprocess_data(line,word_set,tag_set,word_tag_pairs,sequences)\n",
    "\t\n",
    "print( 'done processing data')\n",
    "\n",
    "# #initializing two variables to hold transmission probabilities count of tag1 to tag2\n",
    "# def populate_transmission_probabilities(transmission_probabilities):\n",
    "\t# for i in tag_set:\n",
    "\t\t# transmission_probabilities[\"startto%(i)s\" %locals()] = 0.0\n",
    "\t\t# transmission_probabilities[\"%(i)stoend\" %locals()] = 0.0\n",
    "\t\t# for j in tag_set:\n",
    "\t\t\t# transmission_probabilities[\"%(i)sto%(j)s\" % locals()] = 0.0\n",
    "\t\t\t\n",
    "#transmission_probabilities = {}\n",
    "#count_tag_giventags = copy.deepcopy(transmission_probabilities)\n",
    "\n",
    "def incr_dict_count(dict, key1, key2=None):\n",
    "\tif key2 is None:\n",
    "\t\tkey = key1 \n",
    "\telse:\n",
    "\t\tkey = str(key1)+ '_*_' + str(key2) #special splitter that should not be replicated by any of the tags\n",
    "\tif key in dict:\n",
    "\t\tdict[key] += 1\n",
    "\telse:\n",
    "\t\tdict[key] = 1\n",
    "def get_dict_count(dict, key1, key2=None):\n",
    "\tif key2 is None:\n",
    "\t\tkey = key1 \n",
    "\telse:\n",
    "\t\t#print(key1)\n",
    "\t\t#print(key2)        \n",
    "\t\tkey = str(key1)+ '_*_' + str(key2) #special splitter that should not be replicated by any of the tags\n",
    "\tif (key in dict):\n",
    "\t\treturn dict[key]\n",
    "\treturn 0\n",
    "\n",
    "#initialize and populate dictionary to hold emission count [word, tag]\n",
    "def get_count_word_tag(count_word_tag):\n",
    "\tfor pair in word_tag_pairs:\n",
    "\t\tincr_dict_count(count_word_tag, pair[0], pair[1])\n",
    "\t\t\t\n",
    "\treturn count_word_tag\n",
    "\n",
    "#populates tag_count\n",
    "def get_tag_count(sequences):\n",
    "\ttag_count = {}\n",
    "\n",
    "\tfor sequence in sequences:\n",
    "\t\tfor element in sequence:\n",
    "\t\t\ttag = element.split()[1]\n",
    "\t\t\tincr_dict_count(tag_count, str(tag))\n",
    "\t\tincr_dict_count(tag_count, 'Start')\n",
    "\t\tincr_dict_count(tag_count, 'End')\n",
    "\treturn tag_count\n",
    "\n",
    "#sequences are broken at .\n",
    "#count discriminative transmission probabilities based on n nearest tags, populating count_tag_giventags [tag, tag_sequence]\n",
    "#special tags are -- for no tags (before or after start) ** for the tag's location, and ?? for any tag (independent) <- this last one is not used in current implementation\n",
    "def get_count_tag_giventags(sequences, n=1):\n",
    "\tcount_tag_giventags = {}\n",
    "\tgiventags_count = {}\n",
    "\tfor seq in sequences:\n",
    "\t\tseq2 = []\n",
    "\t\thelper = []\n",
    "\t\tfor element in range(len(seq)):\n",
    "\t\t\ttag = seq[element].split()[1]\n",
    "\t\t\thelper.append(seq[element])\n",
    "\t\t\tif tag == '.' or element == len(seq)-1:\n",
    "\t\t\t\tseq2.append(helper)\n",
    "\t\t\t\thelper = []\n",
    "\t\tfor sequence in seq2:\n",
    "\t\t\tfor element in range(len(sequence)):\n",
    "\t\t\t\tfor _n in range(1,n+1): #have all n values\n",
    "\t\t\t\t\ttag = sequence[element].split()[1]\n",
    "\t\t\t\t\tkey = [sequence[i].split()[1] for i in range(max(0,element-_n),min(len(sequence),element+_n+1))] #limit to within sequence range\n",
    "\t\t\t\t\tkey[_n if element-_n>0 else element] = '**'\n",
    "\t\t\t\t\tstring_key = str(key)\n",
    "\t\t\t\t\tincr_dict_count(count_tag_giventags, tag, string_key)\n",
    "\t\t\t\t\tincr_dict_count(giventags_count, string_key)\n",
    "\t\t\t\t\t#left and right wildcards\n",
    "\t\t\t\t\tif (key[0]!='**'):\n",
    "\t\t\t\t\t\tstring_key = str(['??' if k<1 else key[k] for k in range(len(key))])\n",
    "\t\t\t\t\t\tincr_dict_count(count_tag_giventags, tag, string_key)\n",
    "\t\t\t\t\t\tincr_dict_count(giventags_count, string_key)\n",
    "\t\t\t\t\tif (key[-1]!='**'):\n",
    "\t\t\t\t\t\tstring_key = str(['??' if k>len(key)-2 else key[k] for k in range(len(key))])\n",
    "\t\t\t\t\t\tincr_dict_count(count_tag_giventags, tag, string_key)\n",
    "\t\t\t\t\t\tincr_dict_count(giventags_count, string_key)\n",
    "\treturn count_tag_giventags, giventags_count\n",
    "\n",
    "#compute emission probabilities based on word_count_tag and tag_count\n",
    "def get_emission_probabilities(count_word_tag,tag_count):\n",
    "\temission_probabilities = {}\n",
    "\n",
    "\tfor word_tag in count_word_tag.keys():\n",
    "\t\ttag = word_tag.rsplit(\"_*_\",1)[1] #splitting using special splitter\n",
    "\t\temission_probabilities[word_tag] = float(count_word_tag[word_tag])/tag_count[tag]\n",
    "\treturn emission_probabilities\n",
    "\n",
    "new_word_set_mapper = {}\n",
    "#Handle new words by adding them to emission table and guessing what they are.\n",
    "#Special cases includes USR (@), URL (http://), HT (#)\n",
    "#lazy handling maps word to existing word in word_set\n",
    "#Break word into 2. e.g, word='word' --> (ord), (w, rd), (wo, d), (wor)\n",
    "#if a word in word_set contains both, add them to a set. Priority is based on length.\n",
    "def new_word(word):\n",
    "\tif (word not in new_word_set_mapper.keys()):\n",
    "\t\tword_permutation1 = []\n",
    "\t\tword_permutation2 = []\n",
    "\t\tfor i in range(len(word)):\n",
    "\t\t\tword_permutation1.append(word[0:i])\n",
    "\t\t\tword_permutation2.append(word[i+1:len(word)])\n",
    "\t\tbest_match = word_set[0] #default\n",
    "\t\tbest_score = -9999\n",
    "\t\tfor w in word_set:\n",
    "\t\t\tscore = -(len(w)-len(word))**2 #negative number\n",
    "\t\t\tfor wp1 in word_permutation1:\n",
    "\t\t\t\tif (wp1!='' and (wp1 in w)):\n",
    "\t\t\t\t\tscore+=len(wp1)\n",
    "\t\t\tfor wp2 in word_permutation2:\n",
    "\t\t\t\tif (wp2!='' and (wp2 in w)):\n",
    "\t\t\t\t\tscore+=len(wp2)\n",
    "\t\t\tif (score > best_score):\n",
    "\t\t\t\tbest_match = w\n",
    "\t\t\t\tbest_score = score\n",
    "\t\t\t\t#print( 'score: ', score, word, w\n",
    "\t\t#print( 'new map! ', word, '-->', best_match\n",
    "\t\tnew_word_set_mapper[word] = best_match\n",
    "\treturn new_word_set_mapper[word]\n",
    "\n",
    "#get emission probability from emission_probabilities given a word and a tag\n",
    "def get_emission_probability(emission_probabilities, tag_count, word, tag):\n",
    "\tkey = word + \"_*_\" + tag\n",
    "\tif \tkey in emission_probabilities.keys():\n",
    "\t\treturn emission_probabilities[key]\n",
    "\telse:\n",
    "\t\tif (not word in word_set): #new word\n",
    "\t\t\tif (word[0]=='@'):\n",
    "\t\t\t\treturn 1.0 if (tag=='USR') else 0.0\n",
    "\t\t\telif (word[:7]=='http://' or word[:8]=='https://'):\n",
    "\t\t\t\treturn 1.0 if (tag=='URL') else 0.0\n",
    "\t\t\telif (word[0]=='#'):\n",
    "\t\t\t\treturn 1.0 if (tag=='HT') else 0.0\n",
    "\t\t\t#redirect to closest matched word\n",
    "\t\t\treturn get_emission_probability(emission_probabilities, tag_count, new_word(word), tag)\n",
    "\t\t\t# elif (tag=='VBG'):\n",
    "\t\t\t\t# if (word[-3:]=='ing'):\n",
    "\t\t\t\t\t# return 1.0/(tag_count[tag]+1)\n",
    "\t\t\t# elif (tag=='VBD'):\n",
    "\t\t\t\t# if (word[-2:]=='ed'):\n",
    "\t\t\t\t\t# return 1.0/(tag_count[tag]+1)\n",
    "\t\t\t\t# elif (word[-1]=='d'):\n",
    "\t\t\t\t\t# return 0.5/(tag_count[tag]+1)\n",
    "\t\t\t# #TODO: find closest match\n",
    "\t\t\t# return 0.25/(tag_count[tag]+1) #1/(tag_count+1)\n",
    "\t\t#return 1.0/(tag_count[tag]+1) #1/(tag_count+1)\n",
    "\t\treturn 1.0/(sum(tag_count.values())+1) #1/(#ofWords+1)\n",
    "\n",
    "# def pos_tagger(word_list):\n",
    "\t# global emission_probabilities\n",
    "\t# global tag_count\n",
    "\t# global tag_set\n",
    "\n",
    "\t# predicted_word_tag = []\n",
    "\t# for word in word_list:\n",
    "\t\t# chosen_tag = \"\"\n",
    "\t\t# max_emission_value = 0\n",
    "\t\t# for tag in tag_set:\n",
    "\t\t\t# emission_value = get_emission_probability(emission_probabilities,tag_count,word,tag)\n",
    "\t\t\t# if emission_value>max_emission_value:\n",
    "\t\t\t\t# max_emission_value = emission_value\n",
    "\t\t\t\t# chosen_tag = tag\n",
    "\t\t# predicted_word_tag.append([word,chosen_tag])\n",
    "\t# return predicted_word_tag\n",
    "\n",
    "#compute transmission probabilities based on count_tag_giventags and giventags_count\n",
    "def get_transmission_probabilities(count_tag_giventags,giventags_count):\n",
    "\ttransmission_probabilities = {}\n",
    "\tfor tp in count_tag_giventags.keys():\n",
    "\t\tx = tp.split(\"_*_\")\n",
    "\t\ttag = x[0]\n",
    "\t\tnext_tags = x[1]\n",
    "\t\ttrans_prob = float(count_tag_giventags[tp])/giventags_count[next_tags]\n",
    "\t\t#unbiased probability\n",
    "\t\ttransmission_probabilities[tp] = (trans_prob * giventags_count[next_tags])/(giventags_count[next_tags]+10)\n",
    "\treturn transmission_probabilities\n",
    "\n",
    "#get transmission probability given some tags\n",
    "#refer to get_count_tag_giventags for the complicated details\n",
    "def get_transmission_probability(transmission_probabilities,tag_index,tag_sequence,n,trim='n'):\n",
    "\tglobal tag_count \n",
    "\t\n",
    "\ttag = tag_sequence[tag_index]\n",
    "\tif tag == None:\n",
    "\t\tprint (tag_sequence)\n",
    "\t\tprint (tag_index)\n",
    "\tkey = [tag_sequence[i] for i in range(max(0,tag_index-n),min(len(tag_sequence),tag_index+n+1))] #limit to within sequence range\n",
    "\tkey[n if tag_index-n>0 else tag_index] = '**'\n",
    "\tif (trim=='l'):\n",
    "\t\tkey[0] = '??'\n",
    "\telif (trim=='r'):\n",
    "\t\tkey[-1] = '??'\n",
    "\tstring_key = str(key)\n",
    "\ttp = get_dict_count(transmission_probabilities, tag, string_key)\n",
    "\tif (tp>0):\n",
    "\t\treturn tp * (1.0 if trim=='n' else 1.0/(giventags_count[string_key]+1))\n",
    "\telse:\n",
    "\t\tif ((key[0]!='**' and key[-1]!='**') or n>1): #trimmable\n",
    "\t\t\tif (trim=='n'): #none\n",
    "\t\t\t\tif (key[0]!='**'):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n, trim='l')\n",
    "\t\t\t\telif(key[-1]!='**'):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n, trim='r')\n",
    "\t\t\t\telif(n>1):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n-1, trim='n')\n",
    "\t\t\telif (trim=='l'): #left trim\n",
    "\t\t\t\tif(key[-1]!='**'):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n, trim='r')\n",
    "\t\t\t\telif(n>1):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n-1, trim='n')\n",
    "\t\t\telse: #right trim\n",
    "\t\t\t\tif(n>1):\n",
    "\t\t\t\t\treturn get_transmission_probability(transmission_probabilities, tag_index, tag_sequence, n-1, trim='n')\n",
    "\t\treturn 1.0/(tag_count[tag]+1)\n",
    "\n",
    "print( 'counting tags...'\t)\t\n",
    "\n",
    "count_word_tag = get_count_word_tag(count_word_tag)\n",
    "\n",
    "tag_count = get_tag_count(sequences)\n",
    "\n",
    "count_tag_giventags, giventags_count = get_count_tag_giventags(sequences, 1)\n",
    "\n",
    "transmission_probabilities = get_transmission_probabilities(count_tag_giventags,giventags_count)\n",
    "\n",
    "emission_probabilities = get_emission_probabilities(count_word_tag,tag_count)\n",
    "\n",
    "print( 'done counting tags.')\n",
    "\n",
    "# for tp, val in transmission_probabilities.items():\n",
    "        # print( tp, '-->', val\n",
    "# for em, val in emission_probabilities.items():\n",
    "        # print( em, '-->', val\n",
    "\t\n",
    "#called by pos_tagger\n",
    "#Obj function of this pos_tagger is trans(given other tags)*emm\n",
    "def sequence_tagger(sequence,tags,transmission_probabilities, tagset, n=1):\n",
    "\tdef objf(_tags=tags, log=False):\n",
    "\t\tret = 0.0\n",
    "\t\tfor element in range(len(_tags)):\n",
    "\t\t\ttp = get_transmission_probability(transmission_probabilities, element, _tags, n)\n",
    "\t\t\tep = get_emission_probability(emission_probabilities, tag_count, sequence[element], _tags[element])\n",
    "\t\t\tret+= (0.1*tp)*ep\n",
    "\t\t\tif (log):\n",
    "\t\t\t\tprint( _tags[element], tp, ep)\n",
    "\t\treturn ret\n",
    "\tinitial_tags = copy.deepcopy(tags)\n",
    "\tbest_objf = objf() # objf(log=True)\n",
    "\tchanged = False #True #change this to true to enable transmission\n",
    "\t# print( sequence\n",
    "\t# print( tags\n",
    "\t# print( 'initial objf:', best_objf\n",
    "\t\n",
    "\twhile(changed):\n",
    "\t\tchanged=False\n",
    "\t\tfor i in range(len(tags)):\n",
    "\t\t\tbest_tag = tags[i]\n",
    "\t\t\tfor tag in tagset:\n",
    "\t\t\t\ttags[i] = tag\n",
    "\t\t\t\t_objf = objf(tags)\n",
    "\t\t\t\tif (_objf>best_objf):\n",
    "\t\t\t\t\tbest_objf = _objf\n",
    "\t\t\t\t\tbest_tag = tag\n",
    "\t\t\t\t\tchanged=True\n",
    "\t\t\ttags[i] = best_tag\n",
    "\t\t#print( 'Changed!:', objf()\n",
    "\t#print( 'final objf:', objf(log=True)\n",
    "\t#print( tags, initial_tags\n",
    "\t\n",
    "\t# brute force\n",
    "\t# max_for_level = len(tags)-1\n",
    "\t# for_level = max_for_level\n",
    "\t# counter = [0]*len(tags)\n",
    "\t# target = len(tagset)\n",
    "\t# while(counter[0]<target):\n",
    "\t\t# while(counter[for_level]<target):\n",
    "\t\t\t# tags[for_level] = tagset[counter[for_level]]\n",
    "\t\t\t# #print( tags\n",
    "\t\t\t# new_objf = objf()\n",
    "\t\t\t# if (new_objf>best_objf):\n",
    "\t\t\t\t# best_objf = new_objf\n",
    "\t\t\t\t# print( best_objf\n",
    "\t\t\t\t# best_tags = copy.deepcopy(tags)\n",
    "\t\t\t# counter[for_level]+=1\n",
    "\t\t\t# while(for_level<max_for_level):\n",
    "\t\t\t\t# for_level+=1\n",
    "\t\t\t\t# counter[for_level]=0\n",
    "\t\t# if (for_level>=0):\n",
    "\t\t\t# for_level = for_level-1\n",
    "\treturn tags\n",
    "\t\n",
    "\t\t\t\n",
    "#Custom made pos_tagger, employing brute force approach to assign tags.\n",
    "#sequences refer to untagged sequence\n",
    "def pos_tagger(sequences):\n",
    "\tglobal transmission_probabilities\n",
    "\tglobal emission_probabilities\n",
    "\tglobal tag_count\n",
    "\t\n",
    "\tsequences_pos_tags = []\n",
    "\tfor seq in sequences:\n",
    "\t\tsequence_pos_tags = []\n",
    "\t\t#initialize tags with the best emission probabilities\n",
    "\t\tfor element in range(len(seq)):\n",
    "\t\t\tbest_initial_tag = [0.0, None]\n",
    "\t\t\tfor tag in tag_count.keys():\n",
    "\t\t\t\tep = get_emission_probability(emission_probabilities, tag_count, seq[element], tag)\n",
    "\t\t\t\tif (ep>=best_initial_tag[0]):\n",
    "\t\t\t\t\tbest_initial_tag = [ep, tag]\n",
    "\t\t\tsequence_pos_tags.append(best_initial_tag[1])\n",
    "\t\t\t\n",
    "\t\tnew_pos_tags = []\n",
    "\t\thelper = 0\n",
    "\t\tfor element in range(len(seq)): #break sequences on .\n",
    "\t\t\ttag = sequence_pos_tags[element]\n",
    "\t\t\t#helper.append(seq[element])\n",
    "\t\t\tif tag == '.' or element == len(seq)-1:\n",
    "\t\t\t\tseq2 = seq[helper:element+1]\n",
    "\t\t\t\tseq2tags = sequence_pos_tags[helper:element+1]\n",
    "\t\t\t\thelper = element+1\n",
    "\t\t\t\t#print( len(seq), seq2tags\n",
    "\t\t\t\ttag_result = sequence_tagger(seq2, seq2tags, transmission_probabilities, tag_count.keys(), 1)\n",
    "\t\t\t\tfor tr in tag_result:\n",
    "\t\t\t\t\tnew_pos_tags.append(tr)\n",
    "\t\tsequences_pos_tags.append(new_pos_tags)\n",
    "\treturn sequences_pos_tags\n",
    "\n",
    "##testing part\n",
    "test_data = \"EN/dev.in\"\n",
    "#test_data = \"pos/ml1.txt\"\n",
    "\n",
    "with open(test_data,\"r\",encoding='utf8') as f:\n",
    "\traw_data = f.read()\n",
    "\n",
    "data = raw_data.split(\"\\n\")\n",
    "\n",
    "test_word_sequences = []\n",
    "sequence = []\n",
    "for i in data: #new sentence\n",
    "\tif i == \"\":\n",
    "\t\ttest_word_sequences.append(sequence)\n",
    "\t\tsequence = []\n",
    "\telse:\n",
    "\t\tsequence.append(i)\n",
    "#removing redundant sequences\n",
    "for i in reversed(test_word_sequences):\n",
    "\tif i != []:\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\ttest_word_sequences.remove(i)\n",
    "\n",
    "sequence_length = []\n",
    "for i in test_word_sequences:\n",
    "\tsequence_length.append(len(i))\n",
    "\n",
    "predicted_word_tag = pos_tagger(test_word_sequences)\n",
    "\n",
    "#Read answer 'tags'\n",
    "def get_actual_tag_sequences(test_output):\n",
    "\ttag=[]\n",
    "\ttags=[]\n",
    "\tfor i in test_output.split(\"\\n\"):\n",
    "\t\tif i != \"\":\n",
    "\t\t\tword = i.split()[0]\n",
    "\t\t\tcurrent_tag = i.split()[1]\n",
    "\t\t\ttag.append(current_tag)\n",
    "\t\telse:\n",
    "\t\t\ttags.append(tag)\n",
    "\t\t\ttag = []\n",
    "\tfor i in reversed(tags):\n",
    "\t\tif i ==[]:\n",
    "\t\t\ttags.remove(i)\n",
    "\treturn tags\n",
    "\n",
    "#write part5\n",
    "p5_file = \"train_dev.p5.out\"\n",
    "#p5_file = \"pos/ml1.out.txt\"\n",
    "\n",
    "def write_to_file(p3_file, test_word_sequences, tag_sequences_p3, raw_data):\n",
    "\tstring = \"\"\n",
    "\tfor i in range(len(test_word_sequences)):\n",
    "\t\tsequence = test_word_sequences[i]\n",
    "\t\tfor element in range(len(sequence)):\n",
    "\t\t\tstring += sequence[element] + \" \" + tag_sequences_p3[i][element] + \"\\n\"\n",
    "\t\tstring+= \"\\n\"\n",
    "\twith open(p3_file, \"w\",encoding='utf8') as f:\n",
    "\t\tf.write(string)\n",
    "\t\t\n",
    "#compute the accuracy of the algorithm\n",
    "def viterbi_acc(l1,l2):\n",
    "\tcount = 0\n",
    "\ttotal_count = 0\n",
    "\tfor i in l1:\n",
    "\t\ttotal_count+=len(i)\n",
    "\tfor i in range(len(l1)):\n",
    "\t\tfor j in range(len(l1[i])):\n",
    "\t\t\t#print( l1[i][j], l2[i][j]\n",
    "\t\t\tif l1[i][j] == l2[i][j]:\n",
    "\t\t\t\tcount+=1\n",
    "\treturn float(count)/total_count\n",
    "\n",
    "# _file = \"pos/dev.out\"\n",
    "# with open(_file, \"r\") as f:\n",
    "\t# test_output = f.read()\n",
    "\t\n",
    "##Comparing Accuracy\n",
    "#actual_tag_sequences = get_actual_tag_sequences(test_output)\n",
    "\n",
    "write_to_file(p5_file,test_word_sequences,predicted_word_tag,raw_data)\n",
    "\n",
    "print( new_word_set_mapper)\n",
    "\n",
    "#print( 'Accuracy:', viterbi_acc(actual_tag_sequences,predicted_word_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, itertools, re, math, operator, os\n",
    "from collections import Counter\n",
    "\n",
    "class part5:\n",
    "    tags = [\"B-negative\",\"B-neutral\",\"B-positive\",\"I-negative\",\"I-neutral\",\"I-positive\",\"O\"]\n",
    "    \n",
    "    def __init__(self,train_words,train_tags,stop_list):\n",
    "        self.train_words = train_words\n",
    "        self.train_tags = train_tags\n",
    "        self.long_train_words =  [j for i in self.train_words for j in i]\n",
    "        self.stop_list = stop_list\n",
    "        self.word_dict = {}\n",
    "        self.preprocessing(train_words,train_tags)\n",
    "        processed_words = [j for i in self.p_words_list for j in i]\n",
    "        #processed_tags = [j for i in self.p_tags_list for j in i]\n",
    "        #self.word_tag_count = Counter(list(zip(processed_words,processed_tags)))\n",
    "        #self.reduce_dict()\n",
    "        \n",
    "        self.word_count = Counter(processed_words)\n",
    "        #print(self.reduce_dict())\n",
    "        #print(len(self.word_count))\n",
    "        #print(self.word_dict)\n",
    "        \n",
    "    def preprocessing(self,train_words,train_tags):\n",
    "        self.p_words_list = []\n",
    "        self.p_tags_list = []\n",
    "\n",
    "        for tweet_index in range(len(train_words)):\n",
    "            tweet_word = train_words[tweet_index]\n",
    "            tweet_tag = train_tags[tweet_index]\n",
    "            processed_word = []\n",
    "            processed_tag = []\n",
    "            \n",
    "            for word_index in range(len(tweet_word)):\n",
    "                word = tweet_word[word_index]\n",
    "                tag = tweet_tag[word_index]\n",
    "                \n",
    "                #removing unnecessary words eg stop words, urls\n",
    "                if word[0] == \"@\" or word[0] == \"#\":\n",
    "                    word = word[1:]\n",
    "                elif word not in self.stop_list and word[0:7]!=\"http://\" and word.isalnum() and not(is_number(word)):\n",
    "                    if len(word)>=5:\n",
    "                        word = self.word_stem(word)\n",
    "                    elif len(word)>=4:\n",
    "                        word = self.remove_repeat(word)\n",
    "                    if word not in self.word_dict:\n",
    "                        self.word_dict[word]= {\"B-negative\":0,\"B-neutral\":0,\"B-positive\":0,\"I-negative\":0,\"I-neutral\":0,\"I-positive\":0,\"O\":0}\n",
    "                    self.word_dict[word][tag]+=1\n",
    "\n",
    "                    #print(self.word_stem(word))\n",
    "                    processed_word.append(word)\n",
    "                    processed_tag.append(tag)\n",
    "                tag_group = []\n",
    "                word_group = []\n",
    "                \n",
    "                for tag_i in range(len(processed_tag)):\n",
    "                    tag = processed_tag[tag_i]\n",
    "                    if tag[0] == \"B\" and tag_group == []:\n",
    "                        tag_group.append(tag)\n",
    "                        word_group.append(processed_word[tag_i])\n",
    "                        \n",
    "                    elif tag[0] == \"B\" and tag_group != []:\n",
    "                        phrase = \" \".join(word_group)\n",
    "                        \n",
    "                        if phrase not in self.word_dict:\n",
    "                            sentiment = tag_group[-1][1:]\n",
    "                            self.word_dict[phrase] = {\"B-negative\":0,\"B-neutral\":0,\"B-positive\":0,\"I-negative\":0,\"I-neutral\":0,\"I-positive\":0,\"O\":0}\n",
    "                        self.word_dict[phrase][\"B\"+sentiment] += 1\n",
    "                        word_group = []\n",
    "                        tag_group = []\n",
    "                    elif tag[0] == \"I\":\n",
    "                        tag_group.append(tag)\n",
    "                        word_group.append(processed_word[tag_i])\n",
    "                    \n",
    "                        \n",
    "                                        \n",
    "            self.p_words_list.append(processed_word)\n",
    "            self.p_tags_list.append(processed_tag)\n",
    "        \n",
    "        #print(p_words_list)\n",
    "        #print(p_tags_list)\n",
    "    def remove_repeat(self,word):\n",
    "        return re.sub(r'(.)\\1{2,}', r'\\1\\1', word)\n",
    "    \n",
    "    def word_stem(self,word):\n",
    "        \n",
    "        n = len(word)\n",
    "        \n",
    "        if word[n-3:] == \"ing\" and word[:n-3] in self.long_train_words:\n",
    "            #print(\"ing!\")\n",
    "            new_word = word[:n-3]          \n",
    "            return new_word\n",
    "        elif word[n-2:] == \"ed\" and word[:n-2] in self.long_train_words:\n",
    "            #print(\"ed!\")\n",
    "            new_word = word[:n-2]\n",
    "            return new_word\n",
    "        elif word[n-1] == \"s\" and word[:n-1] in self.long_train_words:\n",
    "            #print(\"s!\")\n",
    "            new_word = word[:n-1]\n",
    "            return new_word\n",
    "        else:\n",
    "            return word\n",
    "    \n",
    "    def reduce_dict(self):\n",
    "        list_sum = []\n",
    "        for word in self.word_dict:\n",
    "            #print(word)\n",
    "            total = sum(self.word_dict[word].values())\n",
    "            list_sum.append((total,word))\n",
    "        for i in range(len(list_sum)):\n",
    "            if list_sum[i][0]<3:\n",
    "                self.word_dict.pop(word,None)\n",
    "        return list_sum\n",
    "    \n",
    "    def nb_training(self):\n",
    "        count_label = {}\n",
    "        for tag in self.tags:\n",
    "            count_label[tag] = 0\n",
    "            for word in self.word_dict:\n",
    "                count_label[tag] += self.word_dict[word][tag]\n",
    "        total = sum(count_label.values())\n",
    "        count_label[\"prob\"]={}\n",
    "        for tag in self.tags:\n",
    "            count_label[\"prob\"][tag] = count_label[tag]/total\n",
    "        return count_label\n",
    "            \n",
    "        \n",
    "    def naive_bayes(self,test_data):\n",
    "        train_result = self.nb_training()\n",
    "        predicted_result= []\n",
    "        \n",
    "        for tweet in test_data:\n",
    "            tweet_sentiment = []\n",
    "            predicted_tag = []\n",
    "            prob = 0\n",
    "            for tag in self.tags:\n",
    "                prob = math.log(train_result[\"prob\"][tag])-len(tweet)*math.log(train_result[tag])\n",
    "                \n",
    "                for word in tweet:\n",
    "                                            \n",
    "                    if word in self.word_dict:\n",
    "                        occurence = self.word_dict[word][tag]\n",
    "                        if occurence > 0:\n",
    "                            prob+=math.log(occurence)\n",
    "                        else:\n",
    "                            prob+=math.log(1)\n",
    "                    else:\n",
    "                        prob+=math.log(1)\n",
    "                tweet_sentiment.append((prob,tag))\n",
    "            tweet_sentiment.sort()\n",
    "            #print(tweet_sentiment)\n",
    "            most_probable_sentiment = tweet_sentiment[-1][1]\n",
    "            #print(most_probable_sentiment)\n",
    "            for word in tweet:\n",
    "                if word[0] == \"#\" or word[0] == \"@\":\n",
    "                    if len(word)>=5:\n",
    "                        new_word = self.word_stem(word[1:])\n",
    "                    else:\n",
    "                        new_word = word[1:]\n",
    "                    if new_word in self.word_dict:\n",
    "                        \n",
    "                        new_tag = max(self.word_dict[new_word].items(), key=operator.itemgetter(1))[0]\n",
    "                        #print(new_tag)\n",
    "                        predicted_tag.append(new_tag)\n",
    "                    else:\n",
    "                        predicted_tag.append(most_probable_sentiment)\n",
    "                elif word in self.stop_list or word[0:7]==\"http://\" or not word.isalnum() or is_number(word):\n",
    "                    predicted_tag.append(\"O\")\n",
    "                else:\n",
    "                    new_word = self.word_stem(word)\n",
    "                    if new_word in self.word_dict:\n",
    "                        \n",
    "                        new_tag = max(self.word_dict[new_word].items(), key=operator.itemgetter(1))[0]\n",
    "                        \n",
    "                        predicted_tag.append(new_tag)\n",
    "                    else:\n",
    "                        predicted_tag.append(most_probable_sentiment)\n",
    "            predicted_result.append(predicted_tag)\n",
    "        #print(predicted_result)\n",
    "        return predicted_result"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
