{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exist\n",
      "deleted file\n",
      "time taken = 58.38954043388367s\n"
     ]
    }
   ],
   "source": [
    "import time, os, math\n",
    "from collections import Counter\n",
    "from itertools import count\n",
    "\n",
    "class HMM:\n",
    "\n",
    "    tag_count = {}\n",
    "    word_tag = []\n",
    "    word_tag_em = {}\n",
    "    tags = [\"START\",\"B-negative\",\"B-neutral\",\"B-positive\",\"I-negative\",\"I-neutral\",\"I-positive\",\"O\",\"STOP\"]\n",
    "    new_word_tag = \"\"\n",
    "    start_y = []\n",
    "    y_stop = []\n",
    "    y_sequence = []\n",
    "    \n",
    "    def __init__(self,train_x,train_y):\n",
    "        self.train_x = train_x # train_x is list of words in training data\n",
    "        self.train_y = train_y # train_y is list of tags in training data related to x\n",
    "        self.tag_count = Counter(train_y) # total count for each tag found in training data\n",
    "        self.word_tag = Counter(list(zip(train_x,train_y))) # total count for each word-tag pair found in training data\n",
    "        self.new_word_tag = self.new_word_emission() #find set probability given to new word\n",
    "\n",
    "        # find count for each (prev_tag,current_tag) pair found in training data\n",
    "        self.start_y = train_y[0:len(train_y)-1] \n",
    "        self.y_stop = train_y[1:]        \n",
    "        self.y_sequence = Counter(list(zip(self.start_y,self.y_stop))) \n",
    "        #print(self.y_sequence)\n",
    "        \n",
    "#=========================== PART 2 =============================\n",
    "    #counting number of occurence of y_i\n",
    "    def count_y(self,y_i):                \n",
    "        return self.tag_count[y_i]\n",
    "    \n",
    "    \n",
    "    #2a count(y pair x)/ count(y)\n",
    "    def est_emission(self,x_i,y_i):\n",
    "        return self.word_tag[(x_i,y_i)]\n",
    "    \n",
    "    \n",
    "    #2b emission count(y pair x)/ (count(y)+1)\n",
    "    def impr_est_emission(self,x_i,y_i):\n",
    "        #if tag is START or STOP, emission score for empty word = 1\n",
    "        if y_i == \"START\" or y_i == \"STOP\":\n",
    "            return 1\n",
    "        elif x_i not in self.train_x:\n",
    "            return 1/(self.count_y(y_i)+1)\n",
    "        else:\n",
    "            return self.word_tag[(x_i,y_i)]/(self.count_y(y_i)+1)\n",
    "    \n",
    "    #2b finding tag for new word using estimation 1/ (count(y)+1)   \n",
    "    def new_word_emission(self):\n",
    "        em=[]\n",
    "        for tag in self.tags:  \n",
    "            #ignore \"START\" and \"STOP\"\n",
    "            if tag == \"START\" or tag == \"STOP\":                \n",
    "                em.append(0)\n",
    "            else:\n",
    "                em.append(1/(self.count_y(tag)+1))\n",
    "        #return label using the index of maximum emission found\n",
    "        return self.tags[em.index(max(em))]\n",
    "        \n",
    "    def train(self):\n",
    "        #for each (word,tag) pair, calculate emission score and put in dictionary\n",
    "        for i in self.word_tag:\n",
    "            self.word_tag_em[i]=self.impr_est_emission(i[0],i[1])\n",
    "        return self.word_tag_em\n",
    "            \n",
    "    #2c\n",
    "    def sentiment_analysis(self, test_x):\n",
    "        print(\"predicting...\")\n",
    "        y_star=[]\n",
    "        \n",
    "        #for each word in new training data eg. hello\n",
    "        for word in test_x:\n",
    "            #if word is empty, tag = empty (for score calculation)\n",
    "            if word == \"\":\n",
    "                y_star.append(\"\")\n",
    "                \n",
    "            #if word is new, add predicted tag for new words\n",
    "            elif word not in self.train_x:\n",
    "                y_star.append(self.new_word_tag)\n",
    "            \n",
    "            # otherwise, run through all labels excluding START and STOP to find max emission\n",
    "            else:\n",
    "                em_list = [0] #account for \"START\"\n",
    "                \n",
    "                #for each tag in tags eg. B+, B-, Bn \n",
    "                for tag in self.tags[1:8]:\n",
    "                    # if (word,tag) pair not available in training data; count(word,tag) = 0 hence emission = 0\n",
    "                    if (word,tag) not in self.word_tag_em:\n",
    "                        em_list.append(0)\n",
    "                    # else look up in emission dictionary calculated in train to find score\n",
    "                    else:\n",
    "                        em_list.append(self.word_tag_em[(word,tag)])\n",
    "                # get max emission and corresponding label        \n",
    "                index_of_max = em_list.index(max(em_list))\n",
    "                predicted_tag = self.tags[index_of_max]\n",
    "                \n",
    "                # check if label starts with \"I\". If so, the previous label should start with either \"I\" or \"B\"\n",
    "                # i.e. there should be a previous label and it should not be \"O\" or \"\"\n",
    "                # if not, label should start with \"B\" instead\n",
    "                if predicted_tag[0] == \"I\":\n",
    "                    if y_star[-1]==\"O\" or y_star[-1]==\"\":                           \n",
    "                        predicted_tag = \"B\"+predicted_tag[1:]\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                y_star.append(predicted_tag)\n",
    "                                    \n",
    "        print(\"done predicting!\")\n",
    "        return y_star\n",
    "\n",
    "    \n",
    "#=========================== PART 3 =============================\n",
    "\n",
    "    def count_transition(self,y_prev,y_current):\n",
    "        return self.y_sequence[(y_prev,y_current)]\n",
    "    \n",
    "    def est_transition(self,y_prev,y_current):\n",
    "        if y_prev == \"STOP\" and y_current == \"START\":\n",
    "            return 0\n",
    "        elif (y_prev,y_current) not in self.y_sequence:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.count_transition(y_prev,y_current)/self.count_y(y_prev)\n",
    "\n",
    "        \n",
    "    def viterbi(self,tweet):\n",
    "        n = len(tweet)\n",
    "        possible_path = {} #(current state k, current tag): (prev tag, score from prev tag)\n",
    "        score = 0\n",
    "        optimal_path = []\n",
    "        # for each time step, calculate maximum score and corresponding preceding tag for each current tag\n",
    "        for k in range(n+2):\n",
    "            \n",
    "            #to prevent underflow use log(score) instead\n",
    "            #print(\"k = \"+str(k))\n",
    "            #print(\"word = \"+str(word))\n",
    "            if k == 0:\n",
    "                score = math.log(1)\n",
    "            elif k == 1:\n",
    "                word = tweet[k-1]\n",
    "                for tag in self.tags[1:8]: \n",
    "                    #print(\"current tag = \"+tag)\n",
    "                    a = self.est_transition(\"START\",tag)\n",
    "                    #print(\"a = \"+str(a))\n",
    "                    if (word,tag) in self.word_tag_em:\n",
    "                        b = self.word_tag_em[(word,tag)]\n",
    "                    else:\n",
    "                        b = self.impr_est_emission(word,tag)\n",
    "                    #print(\"b = \"+str(b))\n",
    "                    try:\n",
    "                        score = math.log(a*b)\n",
    "                    except ValueError:\n",
    "                        score = -math.inf\n",
    "                    possible_path[(1,tag)] = (score,\"START\")\n",
    "                    #print(optimal_path[(1,tag)])\n",
    "            elif k <= n:\n",
    "                word = tweet[k-1]\n",
    "                #print(\"\\n==========================================\\n\")\n",
    "                for current_tag in self.tags[1:8]:\n",
    "                    #print(\"\\n----------------------------------------\\n\")\n",
    "                    #print(\"current_tag = \"+current_tag)\n",
    "                    temp = []\n",
    "                    for prev_tag in self.tags[1:8]:\n",
    "                        #print(\"prev_tag = \"+prev_tag)\n",
    "                        a = self.est_transition(prev_tag,current_tag)\n",
    "                        #print(\"a = \"+str(a))\n",
    "                        if (word,prev_tag) in self.word_tag_em:\n",
    "                            b = self.word_tag_em[(word,prev_tag)]\n",
    "                        else:\n",
    "                            b = self.impr_est_emission(word,current_tag)\n",
    "                        #print(\"b = \"+str(b))\n",
    "                        \n",
    "                        try: \n",
    "                            #print(\"prev score = \"+str(optimal_path[(k-1,prev_tag)][0]))\n",
    "                            score = possible_path[(k-1,prev_tag)][0]+math.log(a*b)\n",
    "                            #print(\"score = \"+str(score))\n",
    "                        except ValueError:\n",
    "                            score = -math.inf\n",
    "                            \n",
    "                        if score != -math.inf:                            \n",
    "                            temp.append((score,prev_tag))\n",
    "                    if temp == []:\n",
    "                        possible_path[(k,current_tag)]=(-math.inf,\"O\")\n",
    "                    else:\n",
    "                        optimal_prev_tag = max(temp)[1]\n",
    "                        possible_path[(k,current_tag)]=(max(temp)[0],optimal_prev_tag)\n",
    "            # when k = n+1\n",
    "            else:\n",
    "                temp = []\n",
    "                for tag in self.tags[1:8]: \n",
    "                    a = self.est_transition(tag,\"STOP\")\n",
    "                    #print(\"\\ntag = \"+tag)\n",
    "                    #print(a)\n",
    "                    \n",
    "                    try: \n",
    "                        #print(optimal_path[(k-1,tag)])\n",
    "                        #print(\"\")\n",
    "                        score = possible_path[(k-1,tag)][0]+math.log(a)\n",
    "                    except ValueError:\n",
    "                        score = -math.inf\n",
    "                        \n",
    "                    if score != -math.inf:                            \n",
    "                        temp.append((score,prev_tag))\n",
    "                if temp == []:\n",
    "                    possible_path[(k,\"STOP\")]=(-math.inf,\"O\")\n",
    "                else:\n",
    "                    optimal_prev_tag = max(temp)[1]    \n",
    "                    possible_path[(k,\"STOP\")]=(max(temp)[0],optimal_prev_tag)\n",
    "        current_tag = \"STOP\"\n",
    "        for i in range(n+1,1,-1):            \n",
    "            prev_tag = possible_path[(i,current_tag)][1]\n",
    "            optimal_path.append(prev_tag)\n",
    "            current_tag = prev_tag\n",
    "        #print(possible_path)\n",
    "        #print(optimal_path)\n",
    "        optimal_path.reverse()\n",
    "        #print(optimal_path)\n",
    "        return optimal_path\n",
    "        \n",
    "    def run_viterbi(self,test_data):\n",
    "        test_tags = []\n",
    "        for tweet in test_data:\n",
    "            test_tags.append(self.viterbi(tweet))\n",
    "        return test_tags\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# format: [[words], [tags]]\n",
    "def read_train(file_name):\n",
    "    in_file = open(file_name,'r',encoding='utf8')\n",
    "    l = []\n",
    "    words = [\"\"]\n",
    "    tags = [\"START\"]\n",
    "    for line in in_file:\n",
    "        x = line.strip().split()\n",
    "        if x != []:\n",
    "            words.append(x[0])\n",
    "            tags.append(x[1].rstrip('\\n'))\n",
    "        else:\n",
    "            words.append(\"\")\n",
    "            tags.append(\"STOP\")\n",
    "            words.append(\"\")\n",
    "            tags.append(\"START\")\n",
    "    tags=tags[0:len(tags)-1]\n",
    "    words = words[0:len(words)-1]\n",
    "    l.append(words)\n",
    "    l.append(tags)\n",
    "    in_file.close()\n",
    "    return l\n",
    "    \n",
    "#reading and writing to files \n",
    "# format:[[tweet1][tweet2]....]\n",
    "def read_dev_in(file_name):\n",
    "    in_file = open(file_name,'r',encoding='utf8')\n",
    "    l = []\n",
    "    tweet = []\n",
    "    for line in in_file:\n",
    "        tweet.append(line.strip())\n",
    "        if line.strip()==\"\":\n",
    "            tweet.remove(\"\")\n",
    "            l.append(tweet)\n",
    "            tweet=[]\n",
    "                \n",
    "        \n",
    "    in_file.close()\n",
    "    return l\n",
    "\n",
    "def write_devp2(language,word_list,tag_list):\n",
    "    file_name = language+\"/\"+\"dev.p2.out\"\n",
    "    if os.path.isfile(file_name):\n",
    "        print('file exist')\n",
    "        try:\n",
    "            os.remove(file_name)\n",
    "            print(\"deleted file\")\n",
    "        except OSError:\n",
    "            pass\n",
    "    out_file = open(file_name,'a',encoding='utf8')\n",
    "\n",
    "    for i in range(len(word_list)):        \n",
    "        out_file.write(word_list[i]+\" \"+tag_list[i]+\"\\n\")\n",
    "    \n",
    "    out_file.close()\n",
    "        \n",
    "def write_devp3(language,word_list,tag_list):\n",
    "    file_name = language+\"/\"+\"dev.p3c.out\"\n",
    "    if os.path.isfile(file_name):\n",
    "        print('file exist')\n",
    "        try:\n",
    "            os.remove(file_name)\n",
    "            print(\"deleted file\")\n",
    "        except OSError:\n",
    "            print (\"error\")\n",
    "            #pass\n",
    "    out_file = open(file_name,'a',encoding='utf8')\n",
    "\n",
    "    for i in range(len(word_list)): \n",
    "        for j in range(len(word_list[i])):\n",
    "            out_file.write(word_list[i][j]+\" \"+tag_list[i][j]+\"\\n\")\n",
    "        out_file.write(\" \\n\")\n",
    "    \n",
    "    out_file.close()    \n",
    "train_data = read_train(\"EN/train\")\n",
    "test_data = read_dev_in(\"EN/dev.in\")\n",
    "\n",
    "\"\"\"\n",
    "print(train_data[1])\n",
    "print(len(train_data[1]))\n",
    "print(train_data[0])\n",
    "print(len(train_data[0]))\n",
    "\"\"\"\n",
    "part2_HMM = HMM(train_data[0],train_data[1])\n",
    "#print(part2_HMM.train())\n",
    "#print(part2_HMM.sentiment_analysis(test_data))\n",
    "starttime = time.time()\n",
    "#part2_HMM.train()\n",
    "#test_tags = part2_HMM.sentiment_analysis(test_data)\n",
    "#print(test_data)\n",
    "#print(part2_HMM.viterbi(test_data))\n",
    "test_tags = part2_HMM.run_viterbi(test_data)\n",
    "#write_devp2(\"EN\",test_data,test_tags)\n",
    "write_devp3(\"EN\",test_data,test_tags)\n",
    "elapsed = time.time()-starttime\n",
    "\n",
    "print (\"time taken = \"+str(elapsed)+\"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
